<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8" data-next-head=""/><meta name="viewport" content="width=device-width, initial-scale=1" data-next-head=""/><title data-next-head="">Research Papers Repository - Furui Laboratory - Hiroshima University</title><meta name="description" content="A collection of our research publications and academic works." data-next-head=""/><link rel="icon" href="/paper-repository/favicon.ico" sizes="any" data-next-head=""/><link rel="preload" href="/paper-repository/_next/static/css/8a989d8cf645c3d6.css" as="style"/><link rel="stylesheet" href="/paper-repository/_next/static/css/8a989d8cf645c3d6.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" noModule="" src="/paper-repository/_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script src="/paper-repository/_next/static/chunks/webpack-8cbf1f39a0267c5d.js" defer=""></script><script src="/paper-repository/_next/static/chunks/framework-88d0cc4abe8a5763.js" defer=""></script><script src="/paper-repository/_next/static/chunks/main-bbaabd07ecf974de.js" defer=""></script><script src="/paper-repository/_next/static/chunks/pages/_app-218d9da4d77e8bba.js" defer=""></script><script src="/paper-repository/_next/static/chunks/779-a5721b3819a3d0f1.js" defer=""></script><script src="/paper-repository/_next/static/chunks/pages/index-338f5548b3d00a62.js" defer=""></script><script src="/paper-repository/_next/static/J5Z9lYgfd6bhvVj4i3vci/_buildManifest.js" defer=""></script><script src="/paper-repository/_next/static/J5Z9lYgfd6bhvVj4i3vci/_ssgManifest.js" defer=""></script></head><body class="antialiased"><div id="__next"><main><div class="min-h-screen bg-gray-50"><div class="flex-1"><div class="max-w-7xl mx-auto px-4 pt-3 pb-6"><header class="bg-white border-b"><div class="max-w-7xl mx-auto px-4 py-6"><div class="flex flex-col md:flex-row md:justify-between md:items-start gap-6"><div class="space-y-2 flex-1"><div><h1 class="text-xl font-semibold text-gray-900 sm:text-2xl">Intelligent Biosignal Informatics Lab</h1><p class="text-sm text-gray-600 mt-1">Hiroshima University</p></div><div class="md:hidden"><a href="https://home.hiroshima-u.ac.jp/furui/en/" target="_blank" rel="noopener noreferrer" class="inline-flex items-center gap-1 text-sm text-gray-600 hover:text-blue-600 transition-colors"><span>Visit Lab Homepage</span><svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-external-link"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg></a></div><div class="pt-4 space-y-4"><div><h2 class="text-2xl font-bold text-gray-900 sm:text-3xl">Research Papers Repository</h2><p class="text-sm text-gray-600 mt-1">A collection of our research publications and academic works.</p></div><div class="md:hidden"><button class="px-3 py-1.5 text-sm bg-white border rounded-md shadow-sm hover:bg-gray-50 transition-colors">日本語</button></div></div></div><div class="md:flex md:flex-col md:items-end gap-4 hidden"><button class="px-3 py-1.5 text-sm bg-white border rounded-md shadow-sm hover:bg-gray-50 transition-colors">日本語</button><a href="https://home.hiroshima-u.ac.jp/furui/en/" target="_blank" rel="noopener noreferrer" class="group flex flex-col items-end gap-2 hover:no-underline"><div class="relative overflow-hidden rounded-lg w-40 aspect-video shadow-md transition-transform group-hover:scale-105"><img alt="Lab Homepage Preview" loading="lazy" decoding="async" data-nimg="fill" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;color:transparent" src="/paper-repository/images/lab-homepage-en.png"/><div class="absolute inset-0 bg-black/0 group-hover:bg-black/10 transition-colors duration-300"></div></div><div class="flex items-center gap-1 text-sm text-gray-600 group-hover:text-blue-600 transition-colors"><span>Visit Lab Homepage</span><svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-external-link inline"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg></div></a></div></div></div></header><div class="mb-8"><div class="sticky top-0 z-20 bg-white/80 backdrop-blur-sm border-b"><div class="max-w-7xl mx-auto py-4 px-4"><div class="flex flex-wrap items-center gap-4"><div class="flex items-center gap-4 flex-1"><div class="relative flex-1 max-w-md"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-search absolute left-3 top-1/2 -translate-y-1/2 h-4 w-4 text-gray-400"><circle cx="11" cy="11" r="8"></circle><path d="m21 21-4.3-4.3"></path></svg><input class="flex h-10 w-full rounded-md border px-3 py-2 text-sm ring-offset-background file:border-0 file:bg-transparent file:text-sm file:font-medium file:text-foreground placeholder:text-muted-foreground focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:cursor-not-allowed disabled:opacity-50 pl-10 bg-gray-50 border-gray-200" placeholder="Search papers..."/></div><button type="button" role="combobox" aria-controls="radix-:R2aj6:" aria-expanded="false" aria-autocomplete="none" dir="ltr" data-state="closed" class="flex h-10 items-center justify-between rounded-md border border-input px-3 py-2 text-sm ring-offset-background placeholder:text-muted-foreground focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 disabled:cursor-not-allowed disabled:opacity-50 [&amp;&gt;span]:line-clamp-1 w-[140px] bg-white"><span style="pointer-events:none"></span><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-down h-4 w-4 opacity-50" aria-hidden="true"><path d="m6 9 6 6 6-6"></path></svg></button><select aria-hidden="true" tabindex="-1" style="position:absolute;border:0;width:1px;height:1px;padding:0;margin:-1px;overflow:hidden;clip:rect(0, 0, 0, 0);white-space:nowrap;word-wrap:normal"></select></div><div class="flex gap-2"><button class="
                    px-3 py-1.5 rounded-full text-sm font-medium 
                    transition-colors duration-200
                    bg-gray-600 text-white
                  ">All</button><button class="
                    px-3 py-1.5 rounded-full text-sm font-medium 
                    transition-colors duration-200
                    text-blue-600 bg-blue-50 border border-blue-200 hover:bg-blue-100
                  ">Journal</button><button class="
                    px-3 py-1.5 rounded-full text-sm font-medium 
                    transition-colors duration-200
                    text-emerald-600 bg-emerald-50 border border-emerald-200 hover:bg-emerald-100
                  ">International Conf.</button><button class="
                    px-3 py-1.5 rounded-full text-sm font-medium 
                    transition-colors duration-200
                    text-orange-600 bg-orange-50 border border-orange-200 hover:bg-orange-100
                  ">Domestic Conf.</button></div></div></div></div><div class="mt-4"><div class="mb-4"><h3 class="text-sm font-medium text-gray-700 mb-2">Filter by Tags</h3><div class="flex flex-wrap gap-2"><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 text-foreground cursor-pointer">Bayesian Model</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 text-foreground cursor-pointer">Biomimetic Control</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 text-foreground cursor-pointer">Data Generation</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 text-foreground cursor-pointer">Deep Learning</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 text-foreground cursor-pointer">Domain generalization</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 text-foreground cursor-pointer">EEG</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 text-foreground cursor-pointer">EMG</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 text-foreground cursor-pointer">Epileptic Seizure Detection</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 text-foreground cursor-pointer">Infants</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 text-foreground cursor-pointer">Machine Learning</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 text-foreground cursor-pointer">Medical Image/Video</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 text-foreground cursor-pointer">Motion Recognition</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 text-foreground cursor-pointer">Movement Analysis</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 text-foreground cursor-pointer">Piezoelectric Film Sensor</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 text-foreground cursor-pointer">Probabilistic Model</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 text-foreground cursor-pointer">Prosthetic Hand</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 text-foreground cursor-pointer">Reaching Movement</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 text-foreground cursor-pointer">Segmentation</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 text-foreground cursor-pointer">Sleep Analysis</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 text-foreground cursor-pointer">Time-series Analysis</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 text-foreground cursor-pointer">Transfer Learning</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 text-foreground cursor-pointer">Ultrasound Imaging</div></div></div></div></div><div class="grid grid-cols-1 sm:grid-cols-2 md:grid-cols-2 lg:grid-cols-3 xl:grid-cols-3 gap-4"><div class="rounded-lg border text-card-foreground shadow-sm group relative hover:shadow-lg transition-all duration-300 bg-white overflow-hidden" role="article" aria-labelledby="paper-title-epileptic-seizure-detection-using-a-recurrent-neural-network-with-temporal-features-derived-from-a-scale-mixture-eeg-model"><div class="absolute inset-0 cursor-pointer z-10" role="button" tabindex="0" aria-label="View PDF: Epileptic seizure detection using a recurrent neural network with temporal features derived from a scale mixture EEG model"></div><div class="aspect-video overflow-hidden relative"><img alt="Cover image for Epileptic seizure detection using a recurrent neural network with temporal features derived from a scale mixture EEG model" loading="lazy" decoding="async" data-nimg="fill" class="transition-transform duration-300 group-hover:scale-105" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;color:transparent" src="https://drive.google.com/thumbnail?id=1uGnZYP0ZDP6hffBQyV64QEHzeEke0eA4&amp;sz=w2048"/><div class="absolute inset-0 bg-black/50 opacity-0 group-hover:opacity-100 transition-opacity duration-300 flex items-center justify-center"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-file-text w-8 h-8 text-white"><path d="M15 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V7Z"></path><path d="M14 2v4a2 2 0 0 0 2 2h4"></path><path d="M10 9H8"></path><path d="M16 13H8"></path><path d="M16 17H8"></path></svg></div></div><div class="flex flex-col space-y-1.5 relative z-20 p-4"><div class="flex items-center gap-2 mb-2"><span class="text-lg font-medium text-gray-600">2024</span><span class="
      inline-flex items-center px-2.5 py-1 rounded-full text-sm font-medium 
      text-blue-600 bg-blue-50 border-blue-200 border
      transition-colors
    ">Journal</span></div><div><h3 class="tracking-tight text-base font-bold mb-1 cursor-pointer hover:text-blue-600 transition-colors" id="paper-title-epileptic-seizure-detection-using-a-recurrent-neural-network-with-temporal-features-derived-from-a-scale-mixture-eeg-model">Epileptic seizure detection using a recurrent neural network with temporal features derived from a scale mixture EEG model</h3><div class="mb-2"><div class="flex flex-wrap gap-1"><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">Akira Furui</span><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">Ryota Onishi</span><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">...</span><button class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-blue-600 hover:bg-gray-100 border border-gray-100 transition-colors">+2 more</button></div></div><div class="flex items-center gap-2 text-sm mt-1"><div class="relative inline-flex items-center group/venue"><span class="line-clamp-1 text-gray-500">IEEE Access</span></div><span class="text-gray-400">•</span><span class="text-gray-500">2024</span></div></div></div><div class="relative z-20 p-4 pt-0">  <div class="space-y-2.5"><div><button class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800 mb-2 cursor-pointer hover:bg-gray-100 px-2 py-1 rounded-md transition-colors"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-down"><path d="m6 9 6 6 6-6"></path></svg>Abstract</button></div><div class="flex flex-wrap gap-1.5"><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">EEG</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Epileptic Seizure Detection</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Time-series Analysis</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Probabilistic Model</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Deep Learning</div></div><div><button class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800">Show<!-- --> BibTeX</button></div><div class="flex flex-wrap gap-4 mt-3"><div class="flex items-center gap-1 text-sm text-blue-600 hover:text-blue-800 cursor-pointer" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:R3522r6:" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-file-text"><path d="M15 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V7Z"></path><path d="M14 2v4a2 2 0 0 0 2 2h4"></path><path d="M10 9H8"></path><path d="M16 13H8"></path><path d="M16 17H8"></path></svg>PDF</div><a href="https://doi.org/10.1109/ACCESS.2024.3487637" class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800" target="_blank" rel="noopener noreferrer"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-external-link flex-shrink-0"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg>DOI</a></div></div></div></div><div class="rounded-lg border text-card-foreground shadow-sm group relative hover:shadow-lg transition-all duration-300 bg-white overflow-hidden" role="article" aria-labelledby="paper-title-finger-tapping-motion-recognition-based-on-skin-surface-deformation-using-wrist-mounted-piezoelectric-film-sensors"><div class="absolute inset-0 cursor-pointer z-10" role="button" tabindex="0" aria-label="View PDF: Finger-tapping Motion Recognition Based on Skin Surface Deformation Using Wrist-mounted Piezoelectric Film Sensors"></div><div class="aspect-video overflow-hidden relative"><img alt="Cover image for Finger-tapping Motion Recognition Based on Skin Surface Deformation Using Wrist-mounted Piezoelectric Film Sensors" loading="lazy" decoding="async" data-nimg="fill" class="transition-transform duration-300 group-hover:scale-105" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;color:transparent" src="https://drive.google.com/thumbnail?id=1LjcEAKne88LLeDqHegqSZC8sURuMZFxL&amp;sz=w2048"/><div class="absolute inset-0 bg-black/50 opacity-0 group-hover:opacity-100 transition-opacity duration-300 flex items-center justify-center"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-file-text w-8 h-8 text-white"><path d="M15 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V7Z"></path><path d="M14 2v4a2 2 0 0 0 2 2h4"></path><path d="M10 9H8"></path><path d="M16 13H8"></path><path d="M16 17H8"></path></svg></div></div><div class="flex flex-col space-y-1.5 relative z-20 p-4"><div class="flex items-center gap-2 mb-2"><span class="text-lg font-medium text-gray-600">2024</span><span class="
      inline-flex items-center px-2.5 py-1 rounded-full text-sm font-medium 
      text-blue-600 bg-blue-50 border-blue-200 border
      transition-colors
    ">Journal</span></div><div><h3 class="tracking-tight text-base font-bold mb-1 cursor-pointer hover:text-blue-600 transition-colors" id="paper-title-finger-tapping-motion-recognition-based-on-skin-surface-deformation-using-wrist-mounted-piezoelectric-film-sensors">Finger-tapping Motion Recognition Based on Skin Surface Deformation Using Wrist-mounted Piezoelectric Film Sensors</h3><div class="mb-2"><div class="flex flex-wrap gap-1"><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">Shumma Jomyo</span><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">Akira Furui</span><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">...</span><button class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-blue-600 hover:bg-gray-100 border border-gray-100 transition-colors">+3 more</button></div></div><div class="flex items-center gap-2 text-sm mt-1"><div class="relative inline-flex items-center group/venue"><span class="line-clamp-1 text-gray-500">IEEE Sensors Journal</span></div><span class="text-gray-400">•</span><span class="text-gray-500">2024</span></div></div></div><div class="relative z-20 p-4 pt-0">  <div class="space-y-2.5"><div><button class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800 mb-2 cursor-pointer hover:bg-gray-100 px-2 py-1 rounded-md transition-colors"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-down"><path d="m6 9 6 6 6-6"></path></svg>Abstract</button></div><div class="flex flex-wrap gap-1.5"><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Piezoelectric Film Sensor</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Movement Analysis</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Motion Recognition</div></div><div><button class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800">Show<!-- --> BibTeX</button></div><div class="flex flex-wrap gap-4 mt-3"><div class="flex items-center gap-1 text-sm text-blue-600 hover:text-blue-800 cursor-pointer" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:R3524r6:" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-file-text"><path d="M15 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V7Z"></path><path d="M14 2v4a2 2 0 0 0 2 2h4"></path><path d="M10 9H8"></path><path d="M16 13H8"></path><path d="M16 17H8"></path></svg>PDF</div><a href="https://doi.org/10.1109/JSEN.2024.3386333" class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800" target="_blank" rel="noopener noreferrer"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-external-link flex-shrink-0"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg>DOI</a></div></div></div></div><div class="rounded-lg border text-card-foreground shadow-sm group relative hover:shadow-lg transition-all duration-300 bg-white overflow-hidden" role="article" aria-labelledby="paper-title-classification-of-carotid-plaque-with-jellyfish-sign-through-convolutional-and-recurrent-neural-networks-utilizing-plaque-surface-edges"><div class="absolute inset-0 cursor-pointer z-10" role="button" tabindex="0" aria-label="View PDF: Classification of Carotid Plaque with Jellyfish Sign Through Convolutional and Recurrent Neural Networks Utilizing Plaque Surface Edges"></div><div class="aspect-video overflow-hidden relative"><img alt="Cover image for Classification of Carotid Plaque with Jellyfish Sign Through Convolutional and Recurrent Neural Networks Utilizing Plaque Surface Edges" loading="lazy" decoding="async" data-nimg="fill" class="transition-transform duration-300 group-hover:scale-105" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;color:transparent" src="https://drive.google.com/thumbnail?id=1Jk6706l62odCvk56EEaDeqyQqXUt8TBU&amp;sz=w2048"/><div class="absolute inset-0 bg-black/50 opacity-0 group-hover:opacity-100 transition-opacity duration-300 flex items-center justify-center"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-file-text w-8 h-8 text-white"><path d="M15 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V7Z"></path><path d="M14 2v4a2 2 0 0 0 2 2h4"></path><path d="M10 9H8"></path><path d="M16 13H8"></path><path d="M16 17H8"></path></svg></div></div><div class="flex flex-col space-y-1.5 relative z-20 p-4"><div class="flex items-center gap-2 mb-2"><span class="text-lg font-medium text-gray-600">2024</span><span class="
      inline-flex items-center px-2.5 py-1 rounded-full text-sm font-medium 
      text-emerald-600 bg-emerald-50 border-emerald-200 border
      transition-colors
    ">International Conf.</span></div><div><h3 class="tracking-tight text-base font-bold mb-1 cursor-pointer hover:text-blue-600 transition-colors" id="paper-title-classification-of-carotid-plaque-with-jellyfish-sign-through-convolutional-and-recurrent-neural-networks-utilizing-plaque-surface-edges">Classification of Carotid Plaque with Jellyfish Sign Through Convolutional and Recurrent Neural Networks Utilizing Plaque Surface Edges</h3><div class="mb-2"><div class="flex flex-wrap gap-1"><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">Takeshi Yoshidomi</span><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">Shinji Kume</span><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">...</span><button class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-blue-600 hover:bg-gray-100 border border-gray-100 transition-colors">+2 more</button></div></div><div class="flex items-center gap-2 text-sm mt-1"><div class="relative inline-flex items-center group/venue"><span class="line-clamp-1 text-gray-500">EMBC</span></div><span class="text-gray-400">•</span><span class="text-gray-500">2024</span></div></div></div><div class="relative z-20 p-4 pt-0">  <div class="space-y-2.5"><div><button class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800 mb-2 cursor-pointer hover:bg-gray-100 px-2 py-1 rounded-md transition-colors"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-down"><path d="m6 9 6 6 6-6"></path></svg>Abstract</button></div><div class="flex flex-wrap gap-1.5"><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Medical Image/Video</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Ultrasound Imaging</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Deep Learning</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Time-series Analysis</div></div><div><button class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800">Show<!-- --> BibTeX</button></div><div class="flex flex-wrap gap-4 mt-3"><div class="flex items-center gap-1 text-sm text-blue-600 hover:text-blue-800 cursor-pointer" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:R3526r6:" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-file-text"><path d="M15 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V7Z"></path><path d="M14 2v4a2 2 0 0 0 2 2h4"></path><path d="M10 9H8"></path><path d="M16 13H8"></path><path d="M16 17H8"></path></svg>PDF</div><a href="https://doi.org/10.1109/EMBC53108.2024.10782813" class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800" target="_blank" rel="noopener noreferrer"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-external-link flex-shrink-0"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg>DOI</a></div></div></div></div><div class="rounded-lg border text-card-foreground shadow-sm group relative hover:shadow-lg transition-all duration-300 bg-white overflow-hidden" role="article" aria-labelledby="paper-title-inter-subject-variance-transfer-learning-for-emg-pattern-classification-based-on-bayesian-inference"><div class="absolute inset-0 cursor-pointer z-10" role="button" tabindex="0" aria-label="View PDF: Inter-Subject Variance Transfer Learning for EMG Pattern Classification Based on Bayesian Inference"></div><div class="aspect-video overflow-hidden relative"><img alt="Cover image for Inter-Subject Variance Transfer Learning for EMG Pattern Classification Based on Bayesian Inference" loading="lazy" decoding="async" data-nimg="fill" class="transition-transform duration-300 group-hover:scale-105" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;color:transparent" src="https://drive.google.com/thumbnail?id=1uR5T7IzOWOKfq3A19BLkKZx57F6NpAjr&amp;sz=w2048"/><div class="absolute inset-0 bg-black/50 opacity-0 group-hover:opacity-100 transition-opacity duration-300 flex items-center justify-center"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-file-text w-8 h-8 text-white"><path d="M15 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V7Z"></path><path d="M14 2v4a2 2 0 0 0 2 2h4"></path><path d="M10 9H8"></path><path d="M16 13H8"></path><path d="M16 17H8"></path></svg></div></div><div class="flex flex-col space-y-1.5 relative z-20 p-4"><div class="flex items-center gap-2 mb-2"><span class="text-lg font-medium text-gray-600">2024</span><span class="
      inline-flex items-center px-2.5 py-1 rounded-full text-sm font-medium 
      text-emerald-600 bg-emerald-50 border-emerald-200 border
      transition-colors
    ">International Conf.</span></div><div><h3 class="tracking-tight text-base font-bold mb-1 cursor-pointer hover:text-blue-600 transition-colors" id="paper-title-inter-subject-variance-transfer-learning-for-emg-pattern-classification-based-on-bayesian-inference">Inter-Subject Variance Transfer Learning for EMG Pattern Classification Based on Bayesian Inference</h3><div class="mb-2"><div class="flex flex-wrap gap-1"><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">Seitaro Yoneda</span><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">Akira Furui</span></div></div><div class="flex items-center gap-2 text-sm mt-1"><div class="relative inline-flex items-center group/venue"><span class="line-clamp-1 text-gray-500">EMBC</span></div><span class="text-gray-400">•</span><span class="text-gray-500">2024</span></div></div></div><div class="relative z-20 p-4 pt-0">  <div class="space-y-2.5"><div><button class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800 mb-2 cursor-pointer hover:bg-gray-100 px-2 py-1 rounded-md transition-colors"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-down"><path d="m6 9 6 6 6-6"></path></svg>Abstract</button></div><div class="flex flex-wrap gap-1.5"><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">EMG</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Motion Recognition</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Bayesian Model</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Transfer Learning</div></div><div><button class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800">Show<!-- --> BibTeX</button></div><div class="flex flex-wrap gap-4 mt-3"><div class="flex items-center gap-1 text-sm text-blue-600 hover:text-blue-800 cursor-pointer" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:R3528r6:" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-file-text"><path d="M15 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V7Z"></path><path d="M14 2v4a2 2 0 0 0 2 2h4"></path><path d="M10 9H8"></path><path d="M16 13H8"></path><path d="M16 17H8"></path></svg>PDF</div><a href="https://doi.org/10.1109/EMBC53108.2024.10782091" class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800" target="_blank" rel="noopener noreferrer"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-external-link flex-shrink-0"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg>DOI</a></div></div></div></div><div class="rounded-lg border text-card-foreground shadow-sm group relative hover:shadow-lg transition-all duration-300 bg-white overflow-hidden" role="article" aria-labelledby="paper-title-stochastic-fluctuation-in-eeg-evaluated-via-scale-mixture-model-for-decoding-emotional-valence"><div class="absolute inset-0 cursor-pointer z-10" role="button" tabindex="0" aria-label="View PDF: Stochastic Fluctuation in EEG Evaluated via Scale Mixture Model for Decoding Emotional Valence"></div><div class="aspect-video overflow-hidden relative"><img alt="Cover image for Stochastic Fluctuation in EEG Evaluated via Scale Mixture Model for Decoding Emotional Valence" loading="lazy" decoding="async" data-nimg="fill" class="transition-transform duration-300 group-hover:scale-105" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;color:transparent" src="https://drive.google.com/thumbnail?id=1pnms4kRCGqJCmHZn7q0XmzxDbPnKydrL&amp;sz=w2048"/><div class="absolute inset-0 bg-black/50 opacity-0 group-hover:opacity-100 transition-opacity duration-300 flex items-center justify-center"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-file-text w-8 h-8 text-white"><path d="M15 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V7Z"></path><path d="M14 2v4a2 2 0 0 0 2 2h4"></path><path d="M10 9H8"></path><path d="M16 13H8"></path><path d="M16 17H8"></path></svg></div></div><div class="flex flex-col space-y-1.5 relative z-20 p-4"><div class="flex items-center gap-2 mb-2"><span class="text-lg font-medium text-gray-600">2024</span><span class="
      inline-flex items-center px-2.5 py-1 rounded-full text-sm font-medium 
      text-emerald-600 bg-emerald-50 border-emerald-200 border
      transition-colors
    ">International Conf.</span></div><div><h3 class="tracking-tight text-base font-bold mb-1 cursor-pointer hover:text-blue-600 transition-colors" id="paper-title-stochastic-fluctuation-in-eeg-evaluated-via-scale-mixture-model-for-decoding-emotional-valence">Stochastic Fluctuation in EEG Evaluated via Scale Mixture Model for Decoding Emotional Valence</h3><div class="mb-2"><div class="flex flex-wrap gap-1"><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">Shunya Fukuda</span><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">Akira Furui</span><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">...</span><button class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-blue-600 hover:bg-gray-100 border border-gray-100 transition-colors">+2 more</button></div></div><div class="flex items-center gap-2 text-sm mt-1"><div class="relative inline-flex items-center group/venue"><span class="line-clamp-1 text-gray-500">SII</span></div><span class="text-gray-400">•</span><span class="text-gray-500">2024</span></div></div></div><div class="relative z-20 p-4 pt-0">  <div class="space-y-2.5"><div><button class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800 mb-2 cursor-pointer hover:bg-gray-100 px-2 py-1 rounded-md transition-colors"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-down"><path d="m6 9 6 6 6-6"></path></svg>Abstract</button></div><div class="flex flex-wrap gap-1.5"><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">EEG</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Probabilistic Model</div></div><div><button class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800">Show<!-- --> BibTeX</button></div><div class="flex flex-wrap gap-4 mt-3"><div class="flex items-center gap-1 text-sm text-blue-600 hover:text-blue-800 cursor-pointer" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:R352ar6:" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-file-text"><path d="M15 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V7Z"></path><path d="M14 2v4a2 2 0 0 0 2 2h4"></path><path d="M10 9H8"></path><path d="M16 13H8"></path><path d="M16 17H8"></path></svg>PDF</div><a href="https://doi.org/10.1109/SII58957.2024.10417430" class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800" target="_blank" rel="noopener noreferrer"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-external-link flex-shrink-0"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg>DOI</a></div></div></div></div><div class="rounded-lg border text-card-foreground shadow-sm group relative hover:shadow-lg transition-all duration-300 bg-white overflow-hidden" role="article" aria-labelledby="paper-title-プラーク表面情報を活用した深層学習によるjellyfish-sign識別"><div class="aspect-video overflow-hidden relative"><img alt="Cover image for プラーク表面情報を活用した深層学習によるJellyfish sign識別" loading="lazy" decoding="async" data-nimg="fill" class="transition-transform duration-300 group-hover:scale-105" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;color:transparent" src="https://drive.google.com/thumbnail?id=1WEOsjo9MvrdM84AzxjK8q7PbyS73xG99&amp;sz=w2048"/></div><div class="flex flex-col space-y-1.5 relative z-20 p-4"><div class="flex items-center gap-2 mb-2"><span class="text-lg font-medium text-gray-600">2024</span><span class="
      inline-flex items-center px-2.5 py-1 rounded-full text-sm font-medium 
      text-orange-600 bg-orange-50 border-orange-200 border
      transition-colors
    ">Domestic Conf.</span></div><div><h3 class="tracking-tight text-base font-bold mb-1" id="paper-title-プラーク表面情報を活用した深層学習によるjellyfish-sign識別">プラーク表面情報を活用した深層学習によるJellyfish sign識別</h3><div class="mb-2"><div class="flex flex-wrap gap-1"><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">吉冨 孟志</span><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">久米 伸治</span><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">...</span><button class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-blue-600 hover:bg-gray-100 border border-gray-100 transition-colors">+2 more</button></div></div><div class="flex items-center gap-2 text-sm mt-1"><div class="relative inline-flex items-center group/venue"><span class="line-clamp-1 text-gray-500">SI</span></div><span class="text-gray-400">•</span><span class="text-gray-500">2024</span></div></div></div><div class="relative z-20 p-4 pt-0">  <div class="space-y-2.5"><div><button class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800 mb-2 cursor-pointer hover:bg-gray-100 px-2 py-1 rounded-md transition-colors"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-down"><path d="m6 9 6 6 6-6"></path></svg>Abstract</button></div><div class="flex flex-wrap gap-1.5"><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Medical Image/Video</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Ultrasound Imaging</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Deep Learning</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Time-series Analysis</div></div><div><button class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800">Show<!-- --> BibTeX</button></div><div class="flex flex-wrap gap-4 mt-3"></div></div></div></div><div class="rounded-lg border text-card-foreground shadow-sm group relative hover:shadow-lg transition-all duration-300 bg-white overflow-hidden" role="article" aria-labelledby="paper-title-ベイズ逐次自己学習と尺度混合分布を用いた筋電位パターンの適応的分類"><div class="aspect-video overflow-hidden relative"><img alt="Cover image for ベイズ逐次自己学習と尺度混合分布を用いた筋電位パターンの適応的分類" loading="lazy" decoding="async" data-nimg="fill" class="transition-transform duration-300 group-hover:scale-105" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;color:transparent" src="https://drive.google.com/thumbnail?id=1uSt40V_Ll3hWhWoxvJ0hl22iV3YTDf17&amp;sz=w2048"/></div><div class="flex flex-col space-y-1.5 relative z-20 p-4"><div class="flex items-center gap-2 mb-2"><span class="text-lg font-medium text-gray-600">2024</span><span class="
      inline-flex items-center px-2.5 py-1 rounded-full text-sm font-medium 
      text-orange-600 bg-orange-50 border-orange-200 border
      transition-colors
    ">Domestic Conf.</span></div><div><h3 class="tracking-tight text-base font-bold mb-1" id="paper-title-ベイズ逐次自己学習と尺度混合分布を用いた筋電位パターンの適応的分類">ベイズ逐次自己学習と尺度混合分布を用いた筋電位パターンの適応的分類</h3><div class="mb-2"><div class="flex flex-wrap gap-1"><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">米田 清太朗</span><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">古居 彬</span></div></div><div class="flex items-center gap-2 text-sm mt-1"><div class="relative inline-flex items-center group/venue"><span class="line-clamp-1 text-gray-500">SI</span></div><span class="text-gray-400">•</span><span class="text-gray-500">2024</span></div></div></div><div class="relative z-20 p-4 pt-0">  <div class="space-y-2.5"><div><button class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800 mb-2 cursor-pointer hover:bg-gray-100 px-2 py-1 rounded-md transition-colors"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-down"><path d="m6 9 6 6 6-6"></path></svg>Abstract</button></div><div class="flex flex-wrap gap-1.5"><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">EMG</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Bayesian Model</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Machine Learning</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Motion Recognition</div></div><div><button class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800">Show<!-- --> BibTeX</button></div><div class="flex flex-wrap gap-4 mt-3"></div></div></div></div><div class="rounded-lg border text-card-foreground shadow-sm group relative hover:shadow-lg transition-all duration-300 bg-white overflow-hidden" role="article" aria-labelledby="paper-title-敵対的学習に基づく患者不変特徴を利用したてんかん発作検出"><div class="aspect-video overflow-hidden relative"><img alt="Cover image for 敵対的学習に基づく患者不変特徴を利用したてんかん発作検出" loading="lazy" decoding="async" data-nimg="fill" class="transition-transform duration-300 group-hover:scale-105" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;color:transparent" src="https://drive.google.com/thumbnail?id=1VZmhs2_Apo_ZuZD6AJoqthcnFthV9nj1&amp;sz=w2048"/></div><div class="flex flex-col space-y-1.5 relative z-20 p-4"><div class="flex items-center gap-2 mb-2"><span class="text-lg font-medium text-gray-600">2024</span><span class="
      inline-flex items-center px-2.5 py-1 rounded-full text-sm font-medium 
      text-orange-600 bg-orange-50 border-orange-200 border
      transition-colors
    ">Domestic Conf.</span></div><div><h3 class="tracking-tight text-base font-bold mb-1" id="paper-title-敵対的学習に基づく患者不変特徴を利用したてんかん発作検出">敵対的学習に基づく患者不変特徴を利用したてんかん発作検出</h3><div class="mb-2"><div class="flex flex-wrap gap-1"><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">田﨑 莉菜</span><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">矢沢 樹</span><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">...</span><button class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-blue-600 hover:bg-gray-100 border border-gray-100 transition-colors">+3 more</button></div></div><div class="flex items-center gap-2 text-sm mt-1"><div class="relative inline-flex items-center group/venue"><span class="line-clamp-1 text-gray-500">SI</span></div><span class="text-gray-400">•</span><span class="text-gray-500">2024</span></div></div></div><div class="relative z-20 p-4 pt-0">  <div class="space-y-2.5"><div><button class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800 mb-2 cursor-pointer hover:bg-gray-100 px-2 py-1 rounded-md transition-colors"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-down"><path d="m6 9 6 6 6-6"></path></svg>Abstract</button></div><div class="flex flex-wrap gap-1.5"><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">EEG</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Epileptic Seizure Detection</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Deep Learning</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Domain generalization</div></div><div><button class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800">Show<!-- --> BibTeX</button></div><div class="flex flex-wrap gap-4 mt-3"></div></div></div></div><div class="rounded-lg border text-card-foreground shadow-sm group relative hover:shadow-lg transition-all duration-300 bg-white overflow-hidden" role="article" aria-labelledby="paper-title-u-netによる頸動脈超音波動画中のプラーク表面エッジの予測とjellyfish-signの評価"><div class="aspect-video overflow-hidden relative"><img alt="Cover image for U-Netによる頸動脈超音波動画中のプラーク表面エッジの予測とJellyfish signの評価" loading="lazy" decoding="async" data-nimg="fill" class="transition-transform duration-300 group-hover:scale-105" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;color:transparent" src="/paper-repository/images/default-paper-cover.png"/></div><div class="flex flex-col space-y-1.5 relative z-20 p-4"><div class="flex items-center gap-2 mb-2"><span class="text-lg font-medium text-gray-600">2024</span><span class="
      inline-flex items-center px-2.5 py-1 rounded-full text-sm font-medium 
      text-orange-600 bg-orange-50 border-orange-200 border
      transition-colors
    ">Domestic Conf.</span></div><div><h3 class="tracking-tight text-base font-bold mb-1" id="paper-title-u-netによる頸動脈超音波動画中のプラーク表面エッジの予測とjellyfish-signの評価">U-Netによる頸動脈超音波動画中のプラーク表面エッジの予測とJellyfish signの評価</h3><div class="mb-2"><div class="flex flex-wrap gap-1"><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">廣池 友哉</span><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">吉冨 孟志</span><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">...</span><button class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-blue-600 hover:bg-gray-100 border border-gray-100 transition-colors">+3 more</button></div></div><div class="flex items-center gap-2 text-sm mt-1"><div class="relative inline-flex items-center group/venue"><span class="line-clamp-1 text-gray-500">第63回日本生体医工学会大会</span></div><span class="text-gray-400">•</span><span class="text-gray-500">2024</span></div></div></div><div class="relative z-20 p-4 pt-0">  <div class="space-y-2.5"><div><button class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800 mb-2 cursor-pointer hover:bg-gray-100 px-2 py-1 rounded-md transition-colors"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-down"><path d="m6 9 6 6 6-6"></path></svg>Abstract</button></div><div class="flex flex-wrap gap-1.5"><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Medical Image/Video</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Ultrasound Imaging</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Segmentation</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Deep Learning</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Time-series Analysis</div></div><div><button class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800">Show<!-- --> BibTeX</button></div><div class="flex flex-wrap gap-4 mt-3"></div></div></div></div><div class="rounded-lg border text-card-foreground shadow-sm group relative hover:shadow-lg transition-all duration-300 bg-white overflow-hidden" role="article" aria-labelledby="paper-title-bayesian-approach-for-adaptive-emg-pattern-classification-via-semi-supervised-sequential-learning"><div class="absolute inset-0 cursor-pointer z-10" role="button" tabindex="0" aria-label="View PDF: Bayesian Approach for Adaptive EMG Pattern Classification via Semi-supervised Sequential Learning"></div><div class="aspect-video overflow-hidden relative"><img alt="Cover image for Bayesian Approach for Adaptive EMG Pattern Classification via Semi-supervised Sequential Learning" loading="lazy" decoding="async" data-nimg="fill" class="transition-transform duration-300 group-hover:scale-105" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;color:transparent" src="https://drive.google.com/thumbnail?id=1uAee2TeWZW83gupMBi2oWXTE7ILAMXXJ&amp;sz=w2048"/><div class="absolute inset-0 bg-black/50 opacity-0 group-hover:opacity-100 transition-opacity duration-300 flex items-center justify-center"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-file-text w-8 h-8 text-white"><path d="M15 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V7Z"></path><path d="M14 2v4a2 2 0 0 0 2 2h4"></path><path d="M10 9H8"></path><path d="M16 13H8"></path><path d="M16 17H8"></path></svg></div></div><div class="flex flex-col space-y-1.5 relative z-20 p-4"><div class="flex items-center gap-2 mb-2"><span class="text-lg font-medium text-gray-600">2023</span><span class="
      inline-flex items-center px-2.5 py-1 rounded-full text-sm font-medium 
      text-emerald-600 bg-emerald-50 border-emerald-200 border
      transition-colors
    ">International Conf.</span></div><div><h3 class="tracking-tight text-base font-bold mb-1 cursor-pointer hover:text-blue-600 transition-colors" id="paper-title-bayesian-approach-for-adaptive-emg-pattern-classification-via-semi-supervised-sequential-learning">Bayesian Approach for Adaptive EMG Pattern Classification via Semi-supervised Sequential Learning</h3><div class="mb-2"><div class="flex flex-wrap gap-1"><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">Seitaro Yoneda</span><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">Akira Furui</span></div></div><div class="flex items-center gap-2 text-sm mt-1"><div class="relative inline-flex items-center group/venue"><span class="line-clamp-1 text-gray-500">SMC</span></div><span class="text-gray-400">•</span><span class="text-gray-500">2023</span></div></div></div><div class="relative z-20 p-4 pt-0">  <div class="space-y-2.5"><div><button class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800 mb-2 cursor-pointer hover:bg-gray-100 px-2 py-1 rounded-md transition-colors"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-down"><path d="m6 9 6 6 6-6"></path></svg>Abstract</button></div><div class="flex flex-wrap gap-1.5"><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">EMG</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Bayesian Model</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Machine Learning</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Motion Recognition</div></div><div><button class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800">Show<!-- --> BibTeX</button></div><div class="flex flex-wrap gap-4 mt-3"><div class="flex items-center gap-1 text-sm text-blue-600 hover:text-blue-800 cursor-pointer" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:R352kr6:" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-file-text"><path d="M15 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V7Z"></path><path d="M14 2v4a2 2 0 0 0 2 2h4"></path><path d="M10 9H8"></path><path d="M16 13H8"></path><path d="M16 17H8"></path></svg>PDF</div><a href="https://github.com/example/vision-survey" class="flex items-center gap-1 text-sm text-green-600 hover:text-green-800" target="_blank" rel="noopener noreferrer"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-code flex-shrink-0"><polyline points="16 18 22 12 16 6"></polyline><polyline points="8 6 2 12 8 18"></polyline></svg>Code</a><a href="https://doi.org/10.1109/SMC53992.2023.10394290" class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800" target="_blank" rel="noopener noreferrer"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-external-link flex-shrink-0"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg>DOI</a></div></div></div></div><div class="rounded-lg border text-card-foreground shadow-sm group relative hover:shadow-lg transition-all duration-300 bg-white overflow-hidden" role="article" aria-labelledby="paper-title-evaluating-classifier-confidence-for-surface-emg-pattern-recognition"><div class="absolute inset-0 cursor-pointer z-10" role="button" tabindex="0" aria-label="View PDF: Evaluating Classifier Confidence for Surface EMG Pattern Recognition"></div><div class="aspect-video overflow-hidden relative"><img alt="Cover image for Evaluating Classifier Confidence for Surface EMG Pattern Recognition" loading="lazy" decoding="async" data-nimg="fill" class="transition-transform duration-300 group-hover:scale-105" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;color:transparent" src="https://drive.google.com/thumbnail?id=1WLlfs_rA54oyNMYrIaiTDq8ucIn9eeQU&amp;sz=w2048"/><div class="absolute inset-0 bg-black/50 opacity-0 group-hover:opacity-100 transition-opacity duration-300 flex items-center justify-center"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-file-text w-8 h-8 text-white"><path d="M15 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V7Z"></path><path d="M14 2v4a2 2 0 0 0 2 2h4"></path><path d="M10 9H8"></path><path d="M16 13H8"></path><path d="M16 17H8"></path></svg></div></div><div class="flex flex-col space-y-1.5 relative z-20 p-4"><div class="flex items-center gap-2 mb-2"><span class="text-lg font-medium text-gray-600">2023</span><span class="
      inline-flex items-center px-2.5 py-1 rounded-full text-sm font-medium 
      text-emerald-600 bg-emerald-50 border-emerald-200 border
      transition-colors
    ">International Conf.</span></div><div><h3 class="tracking-tight text-base font-bold mb-1 cursor-pointer hover:text-blue-600 transition-colors" id="paper-title-evaluating-classifier-confidence-for-surface-emg-pattern-recognition">Evaluating Classifier Confidence for Surface EMG Pattern Recognition</h3><div class="mb-2"><div class="flex flex-wrap gap-1"><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">Akira Furui</span></div></div><div class="flex items-center gap-2 text-sm mt-1"><div class="relative inline-flex items-center group/venue"><span class="line-clamp-1 text-gray-500">EMBC</span></div><span class="text-gray-400">•</span><span class="text-gray-500">2023</span></div></div></div><div class="relative z-20 p-4 pt-0">  <div class="space-y-2.5"><div><button class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800 mb-2 cursor-pointer hover:bg-gray-100 px-2 py-1 rounded-md transition-colors"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-down"><path d="m6 9 6 6 6-6"></path></svg>Abstract</button></div><div class="flex flex-wrap gap-1.5"><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">EMG</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Machine Learning</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Motion Recognition</div></div><div><button class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800">Show<!-- --> BibTeX</button></div><div class="flex flex-wrap gap-4 mt-3"><div class="flex items-center gap-1 text-sm text-blue-600 hover:text-blue-800 cursor-pointer" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:R352mr6:" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-file-text"><path d="M15 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V7Z"></path><path d="M14 2v4a2 2 0 0 0 2 2h4"></path><path d="M10 9H8"></path><path d="M16 13H8"></path><path d="M16 17H8"></path></svg>PDF</div><a href="https://doi.org/10.1109/EMBC40787.2023.10340977" class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800" target="_blank" rel="noopener noreferrer"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-external-link flex-shrink-0"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg>DOI</a><a href="https://arxiv.org/abs/2304.05898" target="_blank" rel="noopener noreferrer" class="flex items-center gap-1.5 text-sm text-purple-600"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-archive flex-shrink-0"><rect width="20" height="5" x="2" y="3" rx="1"></rect><path d="M4 8v11a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8"></path><path d="M10 12h4"></path></svg>arXiv</a></div></div></div></div><div class="rounded-lg border text-card-foreground shadow-sm group relative hover:shadow-lg transition-all duration-300 bg-white overflow-hidden" role="article" aria-labelledby="paper-title-mixupを利用した筋電位信号の擬似データ生成と複合動作の識別"><div class="absolute inset-0 cursor-pointer z-10" role="button" tabindex="0" aria-label="View PDF: Mixupを利用した筋電位信号の擬似データ生成と複合動作の識別"></div><div class="aspect-video overflow-hidden relative"><img alt="Cover image for Mixupを利用した筋電位信号の擬似データ生成と複合動作の識別" loading="lazy" decoding="async" data-nimg="fill" class="transition-transform duration-300 group-hover:scale-105" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;color:transparent" src="https://drive.google.com/thumbnail?id=1I9aZNR6RK0DvsM7LlgEJgie7KYbW07DN&amp;sz=w2048"/><div class="absolute inset-0 bg-black/50 opacity-0 group-hover:opacity-100 transition-opacity duration-300 flex items-center justify-center"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-file-text w-8 h-8 text-white"><path d="M15 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V7Z"></path><path d="M14 2v4a2 2 0 0 0 2 2h4"></path><path d="M10 9H8"></path><path d="M16 13H8"></path><path d="M16 17H8"></path></svg></div></div><div class="flex flex-col space-y-1.5 relative z-20 p-4"><div class="flex items-center gap-2 mb-2"><span class="text-lg font-medium text-gray-600">2023</span><span class="
      inline-flex items-center px-2.5 py-1 rounded-full text-sm font-medium 
      text-orange-600 bg-orange-50 border-orange-200 border
      transition-colors
    ">Domestic Conf.</span></div><div><h3 class="tracking-tight text-base font-bold mb-1 cursor-pointer hover:text-blue-600 transition-colors" id="paper-title-mixupを利用した筋電位信号の擬似データ生成と複合動作の識別">Mixupを利用した筋電位信号の擬似データ生成と複合動作の識別</h3><div class="mb-2"><div class="flex flex-wrap gap-1"><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">矢沢 樹</span><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">古居 彬</span></div></div><div class="flex items-center gap-2 text-sm mt-1"><div class="relative inline-flex items-center group/venue"><span class="line-clamp-1 text-gray-500">SI</span></div><span class="text-gray-400">•</span><span class="text-gray-500">2023</span></div></div></div><div class="relative z-20 p-4 pt-0">  <div class="space-y-2.5"><div><button class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800 mb-2 cursor-pointer hover:bg-gray-100 px-2 py-1 rounded-md transition-colors"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-down"><path d="m6 9 6 6 6-6"></path></svg>Abstract</button></div><div class="flex flex-wrap gap-1.5"><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">EMG</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Machine Learning</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Motion Recognition</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Data Generation</div></div><div><button class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800">Show<!-- --> BibTeX</button></div><div class="flex flex-wrap gap-4 mt-3"><div class="flex items-center gap-1 text-sm text-blue-600 hover:text-blue-800 cursor-pointer" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:R352or6:" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-file-text"><path d="M15 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V7Z"></path><path d="M14 2v4a2 2 0 0 0 2 2h4"></path><path d="M10 9H8"></path><path d="M16 13H8"></path><path d="M16 17H8"></path></svg>PDF</div></div></div></div></div><div class="rounded-lg border text-card-foreground shadow-sm group relative hover:shadow-lg transition-all duration-300 bg-white overflow-hidden" role="article" aria-labelledby="paper-title-cnn-lstmとプラーク表面情報を用いた超音波動画像中のjellyfish-sign自動識別"><div class="aspect-video overflow-hidden relative"><img alt="Cover image for CNN-LSTMとプラーク表面情報を用いた超音波動画像中のJellyfish Sign自動識別" loading="lazy" decoding="async" data-nimg="fill" class="transition-transform duration-300 group-hover:scale-105" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;color:transparent" src="/paper-repository/images/default-paper-cover.png"/></div><div class="flex flex-col space-y-1.5 relative z-20 p-4"><div class="flex items-center gap-2 mb-2"><span class="text-lg font-medium text-gray-600">2023</span><span class="
      inline-flex items-center px-2.5 py-1 rounded-full text-sm font-medium 
      text-orange-600 bg-orange-50 border-orange-200 border
      transition-colors
    ">Domestic Conf.</span></div><div><h3 class="tracking-tight text-base font-bold mb-1" id="paper-title-cnn-lstmとプラーク表面情報を用いた超音波動画像中のjellyfish-sign自動識別">CNN-LSTMとプラーク表面情報を用いた超音波動画像中のJellyfish Sign自動識別</h3><div class="mb-2"><div class="flex flex-wrap gap-1"><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">吉冨 孟志</span><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">久米 伸治</span><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">...</span><button class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-blue-600 hover:bg-gray-100 border border-gray-100 transition-colors">+2 more</button></div></div><div class="flex items-center gap-2 text-sm mt-1"><div class="relative inline-flex items-center group/venue"><span class="line-clamp-1 text-gray-500">第62回日本生体医工学会大会</span></div><span class="text-gray-400">•</span><span class="text-gray-500">2023</span></div></div></div><div class="relative z-20 p-4 pt-0">  <div class="space-y-2.5"><div><button class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800 mb-2 cursor-pointer hover:bg-gray-100 px-2 py-1 rounded-md transition-colors"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-down"><path d="m6 9 6 6 6-6"></path></svg>Abstract</button></div><div class="flex flex-wrap gap-1.5"><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Medical Image/Video</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Ultrasound Imaging</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Deep Learning</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Time-series Analysis</div></div><div><button class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800">Show<!-- --> BibTeX</button></div><div class="flex flex-wrap gap-4 mt-3"></div></div></div></div><div class="rounded-lg border text-card-foreground shadow-sm group relative hover:shadow-lg transition-all duration-300 bg-white overflow-hidden" role="article" aria-labelledby="paper-title-prediction-of-autistic-tendencies-at-18-months-of-age-via-markerless-video-analysis-of-spontaneous-body-movements-in-4-month-old-infants"><div class="absolute inset-0 cursor-pointer z-10" role="button" tabindex="0" aria-label="View PDF: Prediction of autistic tendencies at 18 months of age via markerless video analysis of spontaneous body movements in 4-month-old infants"></div><div class="aspect-video overflow-hidden relative"><img alt="Cover image for Prediction of autistic tendencies at 18 months of age via markerless video analysis of spontaneous body movements in 4-month-old infants" loading="lazy" decoding="async" data-nimg="fill" class="transition-transform duration-300 group-hover:scale-105" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;color:transparent" src="https://drive.google.com/thumbnail?id=1m4V0_WBlcp2tvKC3zmvoyCM4dX2yyY1a&amp;sz=w2048"/><div class="absolute inset-0 bg-black/50 opacity-0 group-hover:opacity-100 transition-opacity duration-300 flex items-center justify-center"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-file-text w-8 h-8 text-white"><path d="M15 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V7Z"></path><path d="M14 2v4a2 2 0 0 0 2 2h4"></path><path d="M10 9H8"></path><path d="M16 13H8"></path><path d="M16 17H8"></path></svg></div></div><div class="flex flex-col space-y-1.5 relative z-20 p-4"><div class="flex items-center gap-2 mb-2"><span class="text-lg font-medium text-gray-600">2022</span><span class="
      inline-flex items-center px-2.5 py-1 rounded-full text-sm font-medium 
      text-blue-600 bg-blue-50 border-blue-200 border
      transition-colors
    ">Journal</span></div><div><h3 class="tracking-tight text-base font-bold mb-1 cursor-pointer hover:text-blue-600 transition-colors" id="paper-title-prediction-of-autistic-tendencies-at-18-months-of-age-via-markerless-video-analysis-of-spontaneous-body-movements-in-4-month-old-infants">Prediction of autistic tendencies at 18 months of age via markerless video analysis of spontaneous body movements in 4-month-old infants</h3><div class="mb-2"><div class="flex flex-wrap gap-1"><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">Hirokazu Doi</span><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">Naoya Iijima</span><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">...</span><button class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-blue-600 hover:bg-gray-100 border border-gray-100 transition-colors">+7 more</button></div></div><div class="flex items-center gap-2 text-sm mt-1"><div class="relative inline-flex items-center group/venue"><span class="line-clamp-1 text-gray-500">Scientific Reports</span></div><span class="text-gray-400">•</span><span class="text-gray-500">2022</span></div></div></div><div class="relative z-20 p-4 pt-0">  <div class="space-y-2.5"><div><button class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800 mb-2 cursor-pointer hover:bg-gray-100 px-2 py-1 rounded-md transition-colors"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-down"><path d="m6 9 6 6 6-6"></path></svg>Abstract</button></div><div class="flex flex-wrap gap-1.5"><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Medical Image/Video</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Infants</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Movement Analysis</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Machine Learning</div></div><div><button class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800">Show<!-- --> BibTeX</button></div><div class="flex flex-wrap gap-4 mt-3"><div class="flex items-center gap-1 text-sm text-blue-600 hover:text-blue-800 cursor-pointer" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:R352sr6:" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-file-text"><path d="M15 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V7Z"></path><path d="M14 2v4a2 2 0 0 0 2 2h4"></path><path d="M10 9H8"></path><path d="M16 13H8"></path><path d="M16 17H8"></path></svg>PDF</div><a href="https://doi.org/10.1038/s41598-022-21308-y" class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800" target="_blank" rel="noopener noreferrer"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-external-link flex-shrink-0"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg>DOI</a></div></div></div></div><div class="rounded-lg border text-card-foreground shadow-sm group relative hover:shadow-lg transition-all duration-300 bg-white overflow-hidden" role="article" aria-labelledby="paper-title-automated-classification-of-general-movements-in-infants-using-two-stream-spatiotemporal-fusion-network"><div class="absolute inset-0 cursor-pointer z-10" role="button" tabindex="0" aria-label="View PDF: Automated Classification of General Movements in Infants Using Two-stream Spatiotemporal Fusion Network"></div><div class="aspect-video overflow-hidden relative"><img alt="Cover image for Automated Classification of General Movements in Infants Using Two-stream Spatiotemporal Fusion Network" loading="lazy" decoding="async" data-nimg="fill" class="transition-transform duration-300 group-hover:scale-105" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;color:transparent" src="https://drive.google.com/thumbnail?id=1_It8dINmyZ_AU6T_mmtHnBDtdCRCY_Et&amp;sz=w2048"/><div class="absolute inset-0 bg-black/50 opacity-0 group-hover:opacity-100 transition-opacity duration-300 flex items-center justify-center"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-file-text w-8 h-8 text-white"><path d="M15 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V7Z"></path><path d="M14 2v4a2 2 0 0 0 2 2h4"></path><path d="M10 9H8"></path><path d="M16 13H8"></path><path d="M16 17H8"></path></svg></div></div><div class="flex flex-col space-y-1.5 relative z-20 p-4"><div class="flex items-center gap-2 mb-2"><span class="text-lg font-medium text-gray-600">2022</span><span class="
      inline-flex items-center px-2.5 py-1 rounded-full text-sm font-medium 
      text-emerald-600 bg-emerald-50 border-emerald-200 border
      transition-colors
    ">International Conf.</span></div><div><h3 class="tracking-tight text-base font-bold mb-1 cursor-pointer hover:text-blue-600 transition-colors" id="paper-title-automated-classification-of-general-movements-in-infants-using-two-stream-spatiotemporal-fusion-network">Automated Classification of General Movements in Infants Using Two-stream Spatiotemporal Fusion Network</h3><div class="mb-2"><div class="flex flex-wrap gap-1"><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">Yuki Hashimoto</span><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">Akira Furui</span><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">...</span><button class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-blue-600 hover:bg-gray-100 border border-gray-100 transition-colors">+5 more</button></div></div><div class="flex items-center gap-2 text-sm mt-1"><div class="relative inline-flex items-center group/venue"><span class="line-clamp-1 text-gray-500">MICCAI</span></div><span class="text-gray-400">•</span><span class="text-gray-500">2022</span></div></div></div><div class="relative z-20 p-4 pt-0">  <div class="space-y-2.5"><div><button class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800 mb-2 cursor-pointer hover:bg-gray-100 px-2 py-1 rounded-md transition-colors"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-down"><path d="m6 9 6 6 6-6"></path></svg>Abstract</button></div><div class="flex flex-wrap gap-1.5"><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Medical Image/Video</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Movement Analysis</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Infants</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Deep Learning</div></div><div><button class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800">Show<!-- --> BibTeX</button></div><div class="flex flex-wrap gap-4 mt-3"><div class="flex items-center gap-1 text-sm text-blue-600 hover:text-blue-800 cursor-pointer" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:R352ur6:" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-file-text"><path d="M15 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V7Z"></path><path d="M14 2v4a2 2 0 0 0 2 2h4"></path><path d="M10 9H8"></path><path d="M16 13H8"></path><path d="M16 17H8"></path></svg>PDF</div><a href="https://github.com/hashyuki/two-stream-gma" class="flex items-center gap-1 text-sm text-green-600 hover:text-green-800" target="_blank" rel="noopener noreferrer"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-code flex-shrink-0"><polyline points="16 18 22 12 16 6"></polyline><polyline points="8 6 2 12 8 18"></polyline></svg>Code</a><a href="https://doi.org/10.1007/978-3-031-16434-7_72" class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800" target="_blank" rel="noopener noreferrer"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-external-link flex-shrink-0"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg>DOI</a></div></div></div></div><div class="rounded-lg border text-card-foreground shadow-sm group relative hover:shadow-lg transition-all duration-300 bg-white overflow-hidden" role="article" aria-labelledby="paper-title-sleep-eeg-analysis-based-on-a-scale-mixture-model-and-spindle-detection"><div class="absolute inset-0 cursor-pointer z-10" role="button" tabindex="0" aria-label="View PDF: Sleep EEG Analysis Based on a Scale Mixture Model and Spindle Detection"></div><div class="aspect-video overflow-hidden relative"><img alt="Cover image for Sleep EEG Analysis Based on a Scale Mixture Model and Spindle Detection" loading="lazy" decoding="async" data-nimg="fill" class="transition-transform duration-300 group-hover:scale-105" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;color:transparent" src="https://drive.google.com/thumbnail?id=1F0Mr_8CTaoEjv1NgvJ-VAAKXWJRsL9wp&amp;sz=w2048"/><div class="absolute inset-0 bg-black/50 opacity-0 group-hover:opacity-100 transition-opacity duration-300 flex items-center justify-center"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-file-text w-8 h-8 text-white"><path d="M15 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V7Z"></path><path d="M14 2v4a2 2 0 0 0 2 2h4"></path><path d="M10 9H8"></path><path d="M16 13H8"></path><path d="M16 17H8"></path></svg></div></div><div class="flex flex-col space-y-1.5 relative z-20 p-4"><div class="flex items-center gap-2 mb-2"><span class="text-lg font-medium text-gray-600">2022</span><span class="
      inline-flex items-center px-2.5 py-1 rounded-full text-sm font-medium 
      text-emerald-600 bg-emerald-50 border-emerald-200 border
      transition-colors
    ">International Conf.</span></div><div><h3 class="tracking-tight text-base font-bold mb-1 cursor-pointer hover:text-blue-600 transition-colors" id="paper-title-sleep-eeg-analysis-based-on-a-scale-mixture-model-and-spindle-detection">Sleep EEG Analysis Based on a Scale Mixture Model and Spindle Detection</h3><div class="mb-2"><div class="flex flex-wrap gap-1"><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">Miyari Hatamoto</span><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">Akira Furui</span><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">...</span><button class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-blue-600 hover:bg-gray-100 border border-gray-100 transition-colors">+2 more</button></div></div><div class="flex items-center gap-2 text-sm mt-1"><div class="relative inline-flex items-center group/venue"><span class="line-clamp-1 text-gray-500">SII</span></div><span class="text-gray-400">•</span><span class="text-gray-500">2022</span></div></div></div><div class="relative z-20 p-4 pt-0">  <div class="space-y-2.5"><div><button class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800 mb-2 cursor-pointer hover:bg-gray-100 px-2 py-1 rounded-md transition-colors"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-down"><path d="m6 9 6 6 6-6"></path></svg>Abstract</button></div><div class="flex flex-wrap gap-1.5"><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">EEG</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Sleep Analysis</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Probabilistic Model</div></div><div><button class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800">Show<!-- --> BibTeX</button></div><div class="flex flex-wrap gap-4 mt-3"><div class="flex items-center gap-1 text-sm text-blue-600 hover:text-blue-800 cursor-pointer" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:R3530r6:" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-file-text"><path d="M15 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V7Z"></path><path d="M14 2v4a2 2 0 0 0 2 2h4"></path><path d="M10 9H8"></path><path d="M16 13H8"></path><path d="M16 17H8"></path></svg>PDF</div><a href="https://doi.org/10.1109/SII52469.2022.9708856" class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800" target="_blank" rel="noopener noreferrer"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-external-link flex-shrink-0"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg>DOI</a></div></div></div></div><div class="rounded-lg border text-card-foreground shadow-sm group relative hover:shadow-lg transition-all duration-300 bg-white overflow-hidden" role="article" aria-labelledby="paper-title-ベイズ逐次学習に基づく筋電位パターンの適応的分類"><div class="absolute inset-0 cursor-pointer z-10" role="button" tabindex="0" aria-label="View PDF: ベイズ逐次学習に基づく筋電位パターンの適応的分類"></div><div class="aspect-video overflow-hidden relative"><img alt="Cover image for ベイズ逐次学習に基づく筋電位パターンの適応的分類" loading="lazy" decoding="async" data-nimg="fill" class="transition-transform duration-300 group-hover:scale-105" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;color:transparent" src="https://drive.google.com/thumbnail?id=1UonJGSUmmfhVc-4OTw5SpzJmvgLmciIO&amp;sz=w2048"/><div class="absolute inset-0 bg-black/50 opacity-0 group-hover:opacity-100 transition-opacity duration-300 flex items-center justify-center"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-file-text w-8 h-8 text-white"><path d="M15 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V7Z"></path><path d="M14 2v4a2 2 0 0 0 2 2h4"></path><path d="M10 9H8"></path><path d="M16 13H8"></path><path d="M16 17H8"></path></svg></div></div><div class="flex flex-col space-y-1.5 relative z-20 p-4"><div class="flex items-center gap-2 mb-2"><span class="text-lg font-medium text-gray-600">2022</span><span class="
      inline-flex items-center px-2.5 py-1 rounded-full text-sm font-medium 
      text-orange-600 bg-orange-50 border-orange-200 border
      transition-colors
    ">Domestic Conf.</span></div><div><h3 class="tracking-tight text-base font-bold mb-1 cursor-pointer hover:text-blue-600 transition-colors" id="paper-title-ベイズ逐次学習に基づく筋電位パターンの適応的分類">ベイズ逐次学習に基づく筋電位パターンの適応的分類</h3><div class="mb-2"><div class="flex flex-wrap gap-1"><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">米田 清太朗</span><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">古居 彬</span></div></div><div class="flex items-center gap-2 text-sm mt-1"><div class="relative inline-flex items-center group/venue"><span class="line-clamp-1 text-gray-500">SI</span></div><span class="text-gray-400">•</span><span class="text-gray-500">2022</span></div></div></div><div class="relative z-20 p-4 pt-0">  <div class="space-y-2.5"><div><button class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800 mb-2 cursor-pointer hover:bg-gray-100 px-2 py-1 rounded-md transition-colors"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-down"><path d="m6 9 6 6 6-6"></path></svg>Abstract</button></div><div class="flex flex-wrap gap-1.5"><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">EMG</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Bayesian Model</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Machine Learning</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Motion Recognition</div></div><div><button class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800">Show<!-- --> BibTeX</button></div><div class="flex flex-wrap gap-4 mt-3"><div class="flex items-center gap-1 text-sm text-blue-600 hover:text-blue-800 cursor-pointer" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:R3532r6:" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-file-text"><path d="M15 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V7Z"></path><path d="M14 2v4a2 2 0 0 0 2 2h4"></path><path d="M10 9H8"></path><path d="M16 13H8"></path><path d="M16 17H8"></path></svg>PDF</div></div></div></div></div><div class="rounded-lg border text-card-foreground shadow-sm group relative hover:shadow-lg transition-all duration-300 bg-white overflow-hidden" role="article" aria-labelledby="paper-title-emg-pattern-recognition-via-bayesian-inference-with-scale-mixture-based-stochastic-generative-models"><div class="absolute inset-0 cursor-pointer z-10" role="button" tabindex="0" aria-label="View PDF: EMG pattern recognition via Bayesian inference with scale mixture-based stochastic generative models"></div><div class="aspect-video overflow-hidden relative"><img alt="Cover image for EMG pattern recognition via Bayesian inference with scale mixture-based stochastic generative models" loading="lazy" decoding="async" data-nimg="fill" class="transition-transform duration-300 group-hover:scale-105" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;color:transparent" src="https://drive.google.com/thumbnail?id=1Bld1lBrGC7cNdSExRXlFS1QTk9QmaF0B&amp;sz=w2048"/><div class="absolute inset-0 bg-black/50 opacity-0 group-hover:opacity-100 transition-opacity duration-300 flex items-center justify-center"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-file-text w-8 h-8 text-white"><path d="M15 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V7Z"></path><path d="M14 2v4a2 2 0 0 0 2 2h4"></path><path d="M10 9H8"></path><path d="M16 13H8"></path><path d="M16 17H8"></path></svg></div></div><div class="flex flex-col space-y-1.5 relative z-20 p-4"><div class="flex items-center gap-2 mb-2"><span class="text-lg font-medium text-gray-600">2021</span><span class="
      inline-flex items-center px-2.5 py-1 rounded-full text-sm font-medium 
      text-blue-600 bg-blue-50 border-blue-200 border
      transition-colors
    ">Journal</span></div><div><h3 class="tracking-tight text-base font-bold mb-1 cursor-pointer hover:text-blue-600 transition-colors" id="paper-title-emg-pattern-recognition-via-bayesian-inference-with-scale-mixture-based-stochastic-generative-models">EMG pattern recognition via Bayesian inference with scale mixture-based stochastic generative models</h3><div class="mb-2"><div class="flex flex-wrap gap-1"><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">Akira Furui</span><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">Takuya Igaue</span><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">Toshio Tsuji</span></div></div><div class="flex items-center gap-2 text-sm mt-1"><div class="relative inline-flex items-center group/venue"><span class="line-clamp-1 text-gray-500">Expert Systems with Applications</span></div><span class="text-gray-400">•</span><span class="text-gray-500">2021</span></div></div></div><div class="relative z-20 p-4 pt-0">  <div class="space-y-2.5"><div><button class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800 mb-2 cursor-pointer hover:bg-gray-100 px-2 py-1 rounded-md transition-colors"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-down"><path d="m6 9 6 6 6-6"></path></svg>Abstract</button></div><div class="flex flex-wrap gap-1.5"><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">EMG</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Machine Learning</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Motion Recognition</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Bayesian Model</div></div><div><button class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800">Show<!-- --> BibTeX</button></div><div class="flex flex-wrap gap-4 mt-3"><div class="flex items-center gap-1 text-sm text-blue-600 hover:text-blue-800 cursor-pointer" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:R3534r6:" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-file-text"><path d="M15 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V7Z"></path><path d="M14 2v4a2 2 0 0 0 2 2h4"></path><path d="M10 9H8"></path><path d="M16 13H8"></path><path d="M16 17H8"></path></svg>PDF</div><a href="https://doi.org/10.1016/j.eswa.2021.115644" class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800" target="_blank" rel="noopener noreferrer"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-external-link flex-shrink-0"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg>DOI</a></div></div></div></div><div class="rounded-lg border text-card-foreground shadow-sm group relative hover:shadow-lg transition-all duration-300 bg-white overflow-hidden" role="article" aria-labelledby="paper-title-non-gaussianity-detection-of-eeg-signals-based-on-a-multivariate-scale-mixture-model-for-diagnosis-of-epileptic-seizures"><div class="absolute inset-0 cursor-pointer z-10" role="button" tabindex="0" aria-label="View PDF: Non-Gaussianity Detection of EEG Signals Based on a Multivariate Scale Mixture Model for Diagnosis of Epileptic Seizures"></div><div class="aspect-video overflow-hidden relative"><img alt="Cover image for Non-Gaussianity Detection of EEG Signals Based on a Multivariate Scale Mixture Model for Diagnosis of Epileptic Seizures" loading="lazy" decoding="async" data-nimg="fill" class="transition-transform duration-300 group-hover:scale-105" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;color:transparent" src="https://drive.google.com/thumbnail?id=1SpUFpCJiiJoSdxtW0Se2hPg2RjbVSGgD&amp;sz=w2048"/><div class="absolute inset-0 bg-black/50 opacity-0 group-hover:opacity-100 transition-opacity duration-300 flex items-center justify-center"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-file-text w-8 h-8 text-white"><path d="M15 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V7Z"></path><path d="M14 2v4a2 2 0 0 0 2 2h4"></path><path d="M10 9H8"></path><path d="M16 13H8"></path><path d="M16 17H8"></path></svg></div></div><div class="flex flex-col space-y-1.5 relative z-20 p-4"><div class="flex items-center gap-2 mb-2"><span class="text-lg font-medium text-gray-600">2021</span><span class="
      inline-flex items-center px-2.5 py-1 rounded-full text-sm font-medium 
      text-blue-600 bg-blue-50 border-blue-200 border
      transition-colors
    ">Journal</span></div><div><h3 class="tracking-tight text-base font-bold mb-1 cursor-pointer hover:text-blue-600 transition-colors" id="paper-title-non-gaussianity-detection-of-eeg-signals-based-on-a-multivariate-scale-mixture-model-for-diagnosis-of-epileptic-seizures">Non-Gaussianity Detection of EEG Signals Based on a Multivariate Scale Mixture Model for Diagnosis of Epileptic Seizures</h3><div class="mb-2"><div class="flex flex-wrap gap-1"><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">Akira Furui</span><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">Ryota Onishi</span><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">...</span><button class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-blue-600 hover:bg-gray-100 border border-gray-100 transition-colors">+3 more</button></div></div><div class="flex items-center gap-2 text-sm mt-1"><div class="relative inline-flex items-center group/venue"><span class="line-clamp-1 text-gray-500">IEEE TBME</span></div><span class="text-gray-400">•</span><span class="text-gray-500">2021</span></div></div></div><div class="relative z-20 p-4 pt-0">  <div class="space-y-2.5"><div><button class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800 mb-2 cursor-pointer hover:bg-gray-100 px-2 py-1 rounded-md transition-colors"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-down"><path d="m6 9 6 6 6-6"></path></svg>Abstract</button></div><div class="flex flex-wrap gap-1.5"><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">EEG</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Epileptic Seizure Detection</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Probabilistic Model</div></div><div><button class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800">Show<!-- --> BibTeX</button></div><div class="flex flex-wrap gap-4 mt-3"><div class="flex items-center gap-1 text-sm text-blue-600 hover:text-blue-800 cursor-pointer" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:R3536r6:" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-file-text"><path d="M15 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V7Z"></path><path d="M14 2v4a2 2 0 0 0 2 2h4"></path><path d="M10 9H8"></path><path d="M16 13H8"></path><path d="M16 17H8"></path></svg>PDF</div><a href="https://doi.org/10.1109/TBME.2020.3006246" class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800" target="_blank" rel="noopener noreferrer"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-external-link flex-shrink-0"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg>DOI</a></div></div></div></div><div class="rounded-lg border text-card-foreground shadow-sm group relative hover:shadow-lg transition-all duration-300 bg-white overflow-hidden" role="article" aria-labelledby="paper-title-a-time-series-scale-mixture-model-of-eeg-with-a-hidden-markov-structure-for-epileptic-seizure-detection"><div class="absolute inset-0 cursor-pointer z-10" role="button" tabindex="0" aria-label="View PDF: A Time-Series Scale Mixture Model of EEG with a Hidden Markov Structure for Epileptic Seizure Detection"></div><div class="aspect-video overflow-hidden relative"><img alt="Cover image for A Time-Series Scale Mixture Model of EEG with a Hidden Markov Structure for Epileptic Seizure Detection" loading="lazy" decoding="async" data-nimg="fill" class="transition-transform duration-300 group-hover:scale-105" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;color:transparent" src="https://drive.google.com/thumbnail?id=1CP_U8s_VRPv1_WJ_Q-vzpuGasRAscTpw&amp;sz=w2048"/><div class="absolute inset-0 bg-black/50 opacity-0 group-hover:opacity-100 transition-opacity duration-300 flex items-center justify-center"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-file-text w-8 h-8 text-white"><path d="M15 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V7Z"></path><path d="M14 2v4a2 2 0 0 0 2 2h4"></path><path d="M10 9H8"></path><path d="M16 13H8"></path><path d="M16 17H8"></path></svg></div></div><div class="flex flex-col space-y-1.5 relative z-20 p-4"><div class="flex items-center gap-2 mb-2"><span class="text-lg font-medium text-gray-600">2021</span><span class="
      inline-flex items-center px-2.5 py-1 rounded-full text-sm font-medium 
      text-emerald-600 bg-emerald-50 border-emerald-200 border
      transition-colors
    ">International Conf.</span></div><div><h3 class="tracking-tight text-base font-bold mb-1 cursor-pointer hover:text-blue-600 transition-colors" id="paper-title-a-time-series-scale-mixture-model-of-eeg-with-a-hidden-markov-structure-for-epileptic-seizure-detection">A Time-Series Scale Mixture Model of EEG with a Hidden Markov Structure for Epileptic Seizure Detection</h3><div class="mb-2"><div class="flex flex-wrap gap-1"><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">Akira Furui</span><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">Tomoyuki Akiyama</span><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">Toshio Tsuji</span></div></div><div class="flex items-center gap-2 text-sm mt-1"><div class="relative inline-flex items-center group/venue"><span class="line-clamp-1 text-gray-500">EMBC</span></div><span class="text-gray-400">•</span><span class="text-gray-500">2021</span></div></div></div><div class="relative z-20 p-4 pt-0">  <div class="space-y-2.5"><div><button class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800 mb-2 cursor-pointer hover:bg-gray-100 px-2 py-1 rounded-md transition-colors"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-down"><path d="m6 9 6 6 6-6"></path></svg>Abstract</button></div><div class="flex flex-wrap gap-1.5"><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">EEG</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Epileptic Seizure Detection</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Probabilistic Model</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Time-series Analysis</div></div><div><button class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800">Show<!-- --> BibTeX</button></div><div class="flex flex-wrap gap-4 mt-3"><div class="flex items-center gap-1 text-sm text-blue-600 hover:text-blue-800 cursor-pointer" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:R3538r6:" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-file-text"><path d="M15 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V7Z"></path><path d="M14 2v4a2 2 0 0 0 2 2h4"></path><path d="M10 9H8"></path><path d="M16 13H8"></path><path d="M16 17H8"></path></svg>PDF</div><a href="https://doi.org/10.1109/EMBC46164.2021.9630840" class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800" target="_blank" rel="noopener noreferrer"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-external-link flex-shrink-0"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg>DOI</a></div></div></div></div><div class="rounded-lg border text-card-foreground shadow-sm group relative hover:shadow-lg transition-all duration-300 bg-white overflow-hidden" role="article" aria-labelledby="paper-title-biomimetic-control-of-myoelectric-prosthetic-hand-based-on-a-lambda-type-muscle-model"><div class="absolute inset-0 cursor-pointer z-10" role="button" tabindex="0" aria-label="View PDF: Biomimetic Control of Myoelectric Prosthetic Hand Based on a Lambda-type Muscle Model"></div><div class="aspect-video overflow-hidden relative"><img alt="Cover image for Biomimetic Control of Myoelectric Prosthetic Hand Based on a Lambda-type Muscle Model" loading="lazy" decoding="async" data-nimg="fill" class="transition-transform duration-300 group-hover:scale-105" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;color:transparent" src="https://drive.google.com/thumbnail?id=1xEcbFgxXaqKxoZHQbTPS0KHnOU6muq47&amp;sz=w2048"/><div class="absolute inset-0 bg-black/50 opacity-0 group-hover:opacity-100 transition-opacity duration-300 flex items-center justify-center"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-file-text w-8 h-8 text-white"><path d="M15 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V7Z"></path><path d="M14 2v4a2 2 0 0 0 2 2h4"></path><path d="M10 9H8"></path><path d="M16 13H8"></path><path d="M16 17H8"></path></svg></div></div><div class="flex flex-col space-y-1.5 relative z-20 p-4"><div class="flex items-center gap-2 mb-2"><span class="text-lg font-medium text-gray-600">2021</span><span class="
      inline-flex items-center px-2.5 py-1 rounded-full text-sm font-medium 
      text-emerald-600 bg-emerald-50 border-emerald-200 border
      transition-colors
    ">International Conf.</span></div><div><h3 class="tracking-tight text-base font-bold mb-1 cursor-pointer hover:text-blue-600 transition-colors" id="paper-title-biomimetic-control-of-myoelectric-prosthetic-hand-based-on-a-lambda-type-muscle-model">Biomimetic Control of Myoelectric Prosthetic Hand Based on a Lambda-type Muscle Model</h3><div class="mb-2"><div class="flex flex-wrap gap-1"><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">Akira Furui</span><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">Kosuke Nakagaki</span><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">Toshio Tsuji</span></div></div><div class="flex items-center gap-2 text-sm mt-1"><div class="relative inline-flex items-center group/venue"><span class="line-clamp-1 text-gray-500">ICRA</span></div><span class="text-gray-400">•</span><span class="text-gray-500">2021</span></div></div></div><div class="relative z-20 p-4 pt-0">  <div class="space-y-2.5"><div><button class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800 mb-2 cursor-pointer hover:bg-gray-100 px-2 py-1 rounded-md transition-colors"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-down"><path d="m6 9 6 6 6-6"></path></svg>Abstract</button></div><div class="flex flex-wrap gap-1.5"><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">EMG</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Prosthetic Hand</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Biomimetic Control</div></div><div><button class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800">Show<!-- --> BibTeX</button></div><div class="flex flex-wrap gap-4 mt-3"><div class="flex items-center gap-1 text-sm text-blue-600 hover:text-blue-800 cursor-pointer" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:R353ar6:" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-file-text"><path d="M15 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V7Z"></path><path d="M14 2v4a2 2 0 0 0 2 2h4"></path><path d="M10 9H8"></path><path d="M16 13H8"></path><path d="M16 17H8"></path></svg>PDF</div><a href="https://doi.org/10.1109/ICRA48506.2021.9561288" class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800" target="_blank" rel="noopener noreferrer"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-external-link flex-shrink-0"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg>DOI</a></div></div></div></div><div class="rounded-lg border text-card-foreground shadow-sm group relative hover:shadow-lg transition-all duration-300 bg-white overflow-hidden" role="article" aria-labelledby="paper-title-spatiotemporal-parameterization-of-human-reaching-movements-based-on-time-base-generator"><div class="absolute inset-0 cursor-pointer z-10" role="button" tabindex="0" aria-label="View PDF: Spatiotemporal Parameterization of Human Reaching Movements Based on Time Base Generator"></div><div class="aspect-video overflow-hidden relative"><img alt="Cover image for Spatiotemporal Parameterization of Human Reaching Movements Based on Time Base Generator" loading="lazy" decoding="async" data-nimg="fill" class="transition-transform duration-300 group-hover:scale-105" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;color:transparent" src="https://drive.google.com/thumbnail?id=1pf0mB0LryYb8jVW977_NhnBNXA5MH6O1&amp;sz=w2048"/><div class="absolute inset-0 bg-black/50 opacity-0 group-hover:opacity-100 transition-opacity duration-300 flex items-center justify-center"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-file-text w-8 h-8 text-white"><path d="M15 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V7Z"></path><path d="M14 2v4a2 2 0 0 0 2 2h4"></path><path d="M10 9H8"></path><path d="M16 13H8"></path><path d="M16 17H8"></path></svg></div></div><div class="flex flex-col space-y-1.5 relative z-20 p-4"><div class="flex items-center gap-2 mb-2"><span class="text-lg font-medium text-gray-600">2020</span><span class="
      inline-flex items-center px-2.5 py-1 rounded-full text-sm font-medium 
      text-blue-600 bg-blue-50 border-blue-200 border
      transition-colors
    ">Journal</span></div><div><h3 class="tracking-tight text-base font-bold mb-1 cursor-pointer hover:text-blue-600 transition-colors" id="paper-title-spatiotemporal-parameterization-of-human-reaching-movements-based-on-time-base-generator">Spatiotemporal Parameterization of Human Reaching Movements Based on Time Base Generator</h3><div class="mb-2"><div class="flex flex-wrap gap-1"><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">Masanobu Kittaka</span><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">Akira Furui</span><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">...</span><button class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-blue-600 hover:bg-gray-100 border border-gray-100 transition-colors">+3 more</button></div></div><div class="flex items-center gap-2 text-sm mt-1"><div class="relative inline-flex items-center group/venue"><span class="line-clamp-1 text-gray-500">IEEE Access</span></div><span class="text-gray-400">•</span><span class="text-gray-500">2020</span></div></div></div><div class="relative z-20 p-4 pt-0">  <div class="space-y-2.5"><div><button class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800 mb-2 cursor-pointer hover:bg-gray-100 px-2 py-1 rounded-md transition-colors"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-down"><path d="m6 9 6 6 6-6"></path></svg>Abstract</button></div><div class="flex flex-wrap gap-1.5"><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Movement Analysis</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Reaching Movement</div></div><div><button class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800">Show<!-- --> BibTeX</button></div><div class="flex flex-wrap gap-4 mt-3"><div class="flex items-center gap-1 text-sm text-blue-600 hover:text-blue-800 cursor-pointer" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:R353cr6:" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-file-text"><path d="M15 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V7Z"></path><path d="M14 2v4a2 2 0 0 0 2 2h4"></path><path d="M10 9H8"></path><path d="M16 13H8"></path><path d="M16 17H8"></path></svg>PDF</div><a href="https://doi.org/10.1109/ACCESS.2020.3000273" class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800" target="_blank" rel="noopener noreferrer"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-external-link flex-shrink-0"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg>DOI</a></div></div></div></div><div class="rounded-lg border text-card-foreground shadow-sm group relative hover:shadow-lg transition-all duration-300 bg-white overflow-hidden" role="article" aria-labelledby="paper-title-does-the-variance-of-surface-emg-signals-during-isometric-contractions-follow-an-inverse-gamma-distribution?"><div class="absolute inset-0 cursor-pointer z-10" role="button" tabindex="0" aria-label="View PDF: Does the variance of surface EMG signals during isometric contractions follow an inverse gamma distribution?"></div><div class="aspect-video overflow-hidden relative"><img alt="Cover image for Does the variance of surface EMG signals during isometric contractions follow an inverse gamma distribution?" loading="lazy" decoding="async" data-nimg="fill" class="transition-transform duration-300 group-hover:scale-105" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;color:transparent" src="https://drive.google.com/thumbnail?id=10cTjf3ANNJOseGBuC81-yvjMyaxZU7E1&amp;sz=w2048"/><div class="absolute inset-0 bg-black/50 opacity-0 group-hover:opacity-100 transition-opacity duration-300 flex items-center justify-center"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-file-text w-8 h-8 text-white"><path d="M15 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V7Z"></path><path d="M14 2v4a2 2 0 0 0 2 2h4"></path><path d="M10 9H8"></path><path d="M16 13H8"></path><path d="M16 17H8"></path></svg></div></div><div class="flex flex-col space-y-1.5 relative z-20 p-4"><div class="flex items-center gap-2 mb-2"><span class="text-lg font-medium text-gray-600">2020</span><span class="
      inline-flex items-center px-2.5 py-1 rounded-full text-sm font-medium 
      text-emerald-600 bg-emerald-50 border-emerald-200 border
      transition-colors
    ">International Conf.</span></div><div><h3 class="tracking-tight text-base font-bold mb-1 cursor-pointer hover:text-blue-600 transition-colors" id="paper-title-does-the-variance-of-surface-emg-signals-during-isometric-contractions-follow-an-inverse-gamma-distribution?">Does the variance of surface EMG signals during isometric contractions follow an inverse gamma distribution?</h3><div class="mb-2"><div class="flex flex-wrap gap-1"><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">Akira Furui</span><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">Toshio Tsuji</span></div></div><div class="flex items-center gap-2 text-sm mt-1"><div class="relative inline-flex items-center group/venue"><span class="line-clamp-1 text-gray-500">EMBC</span></div><span class="text-gray-400">•</span><span class="text-gray-500">2020</span></div></div></div><div class="relative z-20 p-4 pt-0">  <div class="space-y-2.5"><div><button class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800 mb-2 cursor-pointer hover:bg-gray-100 px-2 py-1 rounded-md transition-colors"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-down"><path d="m6 9 6 6 6-6"></path></svg>Abstract</button></div><div class="flex flex-wrap gap-1.5"><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">EMG</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Probabilistic Model</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Movement Analysis</div></div><div><button class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800">Show<!-- --> BibTeX</button></div><div class="flex flex-wrap gap-4 mt-3"><div class="flex items-center gap-1 text-sm text-blue-600 hover:text-blue-800 cursor-pointer" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:R353er6:" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-file-text"><path d="M15 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V7Z"></path><path d="M14 2v4a2 2 0 0 0 2 2h4"></path><path d="M10 9H8"></path><path d="M16 13H8"></path><path d="M16 17H8"></path></svg>PDF</div><a href="https://doi.org/10.1109/EMBC44109.2020.9176102" class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800" target="_blank" rel="noopener noreferrer"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-external-link flex-shrink-0"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg>DOI</a></div></div></div></div><div class="rounded-lg border text-card-foreground shadow-sm group relative hover:shadow-lg transition-all duration-300 bg-white overflow-hidden" role="article" aria-labelledby="paper-title-a-myoelectric-prosthetic-hand-with-muscle-synergy-based-motion-determination-and-impedance-model-based-biomimetic-control"><div class="absolute inset-0 cursor-pointer z-10" role="button" tabindex="0" aria-label="View PDF: A Myoelectric Prosthetic Hand with Muscle Synergy-based Motion Determination and Impedance Model-based Biomimetic Control"></div><div class="aspect-video overflow-hidden relative"><img alt="Cover image for A Myoelectric Prosthetic Hand with Muscle Synergy-based Motion Determination and Impedance Model-based Biomimetic Control" loading="lazy" decoding="async" data-nimg="fill" class="transition-transform duration-300 group-hover:scale-105" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;color:transparent" src="https://drive.google.com/thumbnail?id=1EIhl_fv9ZbVfg_5ga9QozW8nhTPVP4Bx&amp;sz=w2048"/><div class="absolute inset-0 bg-black/50 opacity-0 group-hover:opacity-100 transition-opacity duration-300 flex items-center justify-center"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-file-text w-8 h-8 text-white"><path d="M15 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V7Z"></path><path d="M14 2v4a2 2 0 0 0 2 2h4"></path><path d="M10 9H8"></path><path d="M16 13H8"></path><path d="M16 17H8"></path></svg></div></div><div class="flex flex-col space-y-1.5 relative z-20 p-4"><div class="flex items-center gap-2 mb-2"><span class="text-lg font-medium text-gray-600">2019</span><span class="
      inline-flex items-center px-2.5 py-1 rounded-full text-sm font-medium 
      text-blue-600 bg-blue-50 border-blue-200 border
      transition-colors
    ">Journal</span></div><div><h3 class="tracking-tight text-base font-bold mb-1 cursor-pointer hover:text-blue-600 transition-colors" id="paper-title-a-myoelectric-prosthetic-hand-with-muscle-synergy-based-motion-determination-and-impedance-model-based-biomimetic-control">A Myoelectric Prosthetic Hand with Muscle Synergy-based Motion Determination and Impedance Model-based Biomimetic Control</h3><div class="mb-2"><div class="flex flex-wrap gap-1"><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">Akira Furui</span><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">Shintaro Eto</span><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">...</span><button class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-blue-600 hover:bg-gray-100 border border-gray-100 transition-colors">+6 more</button></div></div><div class="flex items-center gap-2 text-sm mt-1"><div class="relative inline-flex items-center group/venue"><span class="line-clamp-1 text-gray-500">Science Robotics</span></div><span class="text-gray-400">•</span><span class="text-gray-500">2019</span></div></div></div><div class="relative z-20 p-4 pt-0">  <div class="space-y-2.5"><div><button class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800 mb-2 cursor-pointer hover:bg-gray-100 px-2 py-1 rounded-md transition-colors"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-down"><path d="m6 9 6 6 6-6"></path></svg>Abstract</button></div><div class="flex flex-wrap gap-1.5"><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">EMG</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Machine Learning</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Motion Recognition</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Prosthetic Hand</div></div><div><button class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800">Show<!-- --> BibTeX</button></div><div class="flex flex-wrap gap-4 mt-3"><div class="flex items-center gap-1 text-sm text-blue-600 hover:text-blue-800 cursor-pointer" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:R353gr6:" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-file-text"><path d="M15 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V7Z"></path><path d="M14 2v4a2 2 0 0 0 2 2h4"></path><path d="M10 9H8"></path><path d="M16 13H8"></path><path d="M16 17H8"></path></svg>PDF</div><a href="https://doi.org/10.1126/scirobotics.aaw6339" class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800" target="_blank" rel="noopener noreferrer"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-external-link flex-shrink-0"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg>DOI</a></div></div></div></div><div class="rounded-lg border text-card-foreground shadow-sm group relative hover:shadow-lg transition-all duration-300 bg-white overflow-hidden" role="article" aria-labelledby="paper-title-a-scale-mixture-based-stochastic-model-of-surface-emg-signals-with-variable-variances"><div class="absolute inset-0 cursor-pointer z-10" role="button" tabindex="0" aria-label="View PDF: A Scale Mixture-based Stochastic Model of Surface EMG Signals with Variable Variances"></div><div class="aspect-video overflow-hidden relative"><img alt="Cover image for A Scale Mixture-based Stochastic Model of Surface EMG Signals with Variable Variances" loading="lazy" decoding="async" data-nimg="fill" class="transition-transform duration-300 group-hover:scale-105" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;color:transparent" src="https://drive.google.com/thumbnail?id=1k3gGkdd7_M6X-85WEXPRg7xfVBnxs6NH&amp;sz=w2048"/><div class="absolute inset-0 bg-black/50 opacity-0 group-hover:opacity-100 transition-opacity duration-300 flex items-center justify-center"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-file-text w-8 h-8 text-white"><path d="M15 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V7Z"></path><path d="M14 2v4a2 2 0 0 0 2 2h4"></path><path d="M10 9H8"></path><path d="M16 13H8"></path><path d="M16 17H8"></path></svg></div></div><div class="flex flex-col space-y-1.5 relative z-20 p-4"><div class="flex items-center gap-2 mb-2"><span class="text-lg font-medium text-gray-600">2019</span><span class="
      inline-flex items-center px-2.5 py-1 rounded-full text-sm font-medium 
      text-blue-600 bg-blue-50 border-blue-200 border
      transition-colors
    ">Journal</span></div><div><h3 class="tracking-tight text-base font-bold mb-1 cursor-pointer hover:text-blue-600 transition-colors" id="paper-title-a-scale-mixture-based-stochastic-model-of-surface-emg-signals-with-variable-variances">A Scale Mixture-based Stochastic Model of Surface EMG Signals with Variable Variances</h3><div class="mb-2"><div class="flex flex-wrap gap-1"><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">Akira Furui</span><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">Hideaki Hayashi</span><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">Toshio Tsuji</span></div></div><div class="flex items-center gap-2 text-sm mt-1"><div class="relative inline-flex items-center group/venue"><span class="line-clamp-1 text-gray-500">IEEE TBME</span></div><span class="text-gray-400">•</span><span class="text-gray-500">2019</span></div></div></div><div class="relative z-20 p-4 pt-0">  <div class="space-y-2.5"><div><button class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800 mb-2 cursor-pointer hover:bg-gray-100 px-2 py-1 rounded-md transition-colors"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-down"><path d="m6 9 6 6 6-6"></path></svg>Abstract</button></div><div class="flex flex-wrap gap-1.5"><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">EMG</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Machine Learning</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Motion Recognition</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Probabilistic Model</div></div><div><button class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800">Show<!-- --> BibTeX</button></div><div class="flex flex-wrap gap-4 mt-3"><div class="flex items-center gap-1 text-sm text-blue-600 hover:text-blue-800 cursor-pointer" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:R353ir6:" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-file-text"><path d="M15 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V7Z"></path><path d="M14 2v4a2 2 0 0 0 2 2h4"></path><path d="M10 9H8"></path><path d="M16 13H8"></path><path d="M16 17H8"></path></svg>PDF</div><a href="https://doi.org/10.1109/TBME.2019.2895683" class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800" target="_blank" rel="noopener noreferrer"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-external-link flex-shrink-0"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg>DOI</a></div></div></div></div><div class="rounded-lg border text-card-foreground shadow-sm group relative hover:shadow-lg transition-all duration-300 bg-white overflow-hidden" role="article" aria-labelledby="paper-title-muscle-fatigue-analysis-by-using-a-scale-mixture-based-stochastic-model-of-surface-emg-signals"><div class="absolute inset-0 cursor-pointer z-10" role="button" tabindex="0" aria-label="View PDF: Muscle Fatigue Analysis by Using a Scale Mixture-based Stochastic Model of Surface EMG Signals"></div><div class="aspect-video overflow-hidden relative"><img alt="Cover image for Muscle Fatigue Analysis by Using a Scale Mixture-based Stochastic Model of Surface EMG Signals" loading="lazy" decoding="async" data-nimg="fill" class="transition-transform duration-300 group-hover:scale-105" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;color:transparent" src="https://drive.google.com/thumbnail?id=1S2DW4BX69pzKq22PvFV2VweNRdyh0sE8&amp;sz=w2048"/><div class="absolute inset-0 bg-black/50 opacity-0 group-hover:opacity-100 transition-opacity duration-300 flex items-center justify-center"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-file-text w-8 h-8 text-white"><path d="M15 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V7Z"></path><path d="M14 2v4a2 2 0 0 0 2 2h4"></path><path d="M10 9H8"></path><path d="M16 13H8"></path><path d="M16 17H8"></path></svg></div></div><div class="flex flex-col space-y-1.5 relative z-20 p-4"><div class="flex items-center gap-2 mb-2"><span class="text-lg font-medium text-gray-600">2019</span><span class="
      inline-flex items-center px-2.5 py-1 rounded-full text-sm font-medium 
      text-emerald-600 bg-emerald-50 border-emerald-200 border
      transition-colors
    ">International Conf.</span></div><div><h3 class="tracking-tight text-base font-bold mb-1 cursor-pointer hover:text-blue-600 transition-colors" id="paper-title-muscle-fatigue-analysis-by-using-a-scale-mixture-based-stochastic-model-of-surface-emg-signals">Muscle Fatigue Analysis by Using a Scale Mixture-based Stochastic Model of Surface EMG Signals</h3><div class="mb-2"><div class="flex flex-wrap gap-1"><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">Akira Furui</span><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">Toshio Tsuji</span></div></div><div class="flex items-center gap-2 text-sm mt-1"><div class="relative inline-flex items-center group/venue"><span class="line-clamp-1 text-gray-500">EMBC</span></div><span class="text-gray-400">•</span><span class="text-gray-500">2019</span></div></div></div><div class="relative z-20 p-4 pt-0">  <div class="space-y-2.5"><div><button class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800 mb-2 cursor-pointer hover:bg-gray-100 px-2 py-1 rounded-md transition-colors"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-down"><path d="m6 9 6 6 6-6"></path></svg>Abstract</button></div><div class="flex flex-wrap gap-1.5"><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">EMG</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Probabilistic Model</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Movement Analysis</div></div><div><button class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800">Show<!-- --> BibTeX</button></div><div class="flex flex-wrap gap-4 mt-3"><div class="flex items-center gap-1 text-sm text-blue-600 hover:text-blue-800 cursor-pointer" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:R353kr6:" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-file-text"><path d="M15 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V7Z"></path><path d="M14 2v4a2 2 0 0 0 2 2h4"></path><path d="M10 9H8"></path><path d="M16 13H8"></path><path d="M16 17H8"></path></svg>PDF</div><a href="https://doi.org/10.1109/EMBC.2019.8856348" class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800" target="_blank" rel="noopener noreferrer"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-external-link flex-shrink-0"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg>DOI</a></div></div></div></div><div class="rounded-lg border text-card-foreground shadow-sm group relative hover:shadow-lg transition-all duration-300 bg-white overflow-hidden" role="article" aria-labelledby="paper-title-an-emg-pattern-classification-method-based-on-a-mixture-of-variance-distribution-models"><div class="aspect-video overflow-hidden relative"><img alt="Cover image for An EMG pattern classification method based on a mixture of variance distribution models" loading="lazy" decoding="async" data-nimg="fill" class="transition-transform duration-300 group-hover:scale-105" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;color:transparent" src="https://drive.google.com/thumbnail?id=1wbG1uBFMkckNMouY-NE276_Ui2cX56kg&amp;sz=w2048"/></div><div class="flex flex-col space-y-1.5 relative z-20 p-4"><div class="flex items-center gap-2 mb-2"><span class="text-lg font-medium text-gray-600">2018</span><span class="
      inline-flex items-center px-2.5 py-1 rounded-full text-sm font-medium 
      text-emerald-600 bg-emerald-50 border-emerald-200 border
      transition-colors
    ">International Conf.</span></div><div><h3 class="tracking-tight text-base font-bold mb-1" id="paper-title-an-emg-pattern-classification-method-based-on-a-mixture-of-variance-distribution-models">An EMG pattern classification method based on a mixture of variance distribution models</h3><div class="mb-2"><div class="flex flex-wrap gap-1"><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">Akira Furui</span><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">Hideaki Hayashi</span><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">Toshio Tsuji</span></div></div><div class="flex items-center gap-2 text-sm mt-1"><div class="relative inline-flex items-center group/venue"><span class="line-clamp-1 text-gray-500">EMBC</span></div><span class="text-gray-400">•</span><span class="text-gray-500">2018</span></div></div></div><div class="relative z-20 p-4 pt-0">  <div class="space-y-2.5"><div><button class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800 mb-2 cursor-pointer hover:bg-gray-100 px-2 py-1 rounded-md transition-colors"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-down"><path d="m6 9 6 6 6-6"></path></svg>Abstract</button></div><div class="flex flex-wrap gap-1.5"><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">EMG</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Probabilistic Model</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Motion Recognition</div></div><div><button class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800">Show<!-- --> BibTeX</button></div><div class="flex flex-wrap gap-4 mt-3"><a href="https://doi.org/10.1109/EMBC.2018.8513446" class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800" target="_blank" rel="noopener noreferrer"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-external-link flex-shrink-0"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg>DOI</a></div></div></div></div><div class="rounded-lg border text-card-foreground shadow-sm group relative hover:shadow-lg transition-all duration-300 bg-white overflow-hidden" role="article" aria-labelledby="paper-title-an-artificial-emg-generation-model-based-on-signal-dependent-noise-and-related-application-to-motion-classification"><div class="absolute inset-0 cursor-pointer z-10" role="button" tabindex="0" aria-label="View PDF: An Artificial EMG Generation Model Based on Signal-dependent Noise and Related Application to Motion Classification"></div><div class="aspect-video overflow-hidden relative"><img alt="Cover image for An Artificial EMG Generation Model Based on Signal-dependent Noise and Related Application to Motion Classification" loading="lazy" decoding="async" data-nimg="fill" class="transition-transform duration-300 group-hover:scale-105" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;color:transparent" src="https://drive.google.com/thumbnail?id=19few4HU18Aq-S-pJhmEErLR1osGWaDnA&amp;sz=w2048"/><div class="absolute inset-0 bg-black/50 opacity-0 group-hover:opacity-100 transition-opacity duration-300 flex items-center justify-center"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-file-text w-8 h-8 text-white"><path d="M15 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V7Z"></path><path d="M14 2v4a2 2 0 0 0 2 2h4"></path><path d="M10 9H8"></path><path d="M16 13H8"></path><path d="M16 17H8"></path></svg></div></div><div class="flex flex-col space-y-1.5 relative z-20 p-4"><div class="flex items-center gap-2 mb-2"><span class="text-lg font-medium text-gray-600">2017</span><span class="
      inline-flex items-center px-2.5 py-1 rounded-full text-sm font-medium 
      text-blue-600 bg-blue-50 border-blue-200 border
      transition-colors
    ">Journal</span></div><div><h3 class="tracking-tight text-base font-bold mb-1 cursor-pointer hover:text-blue-600 transition-colors" id="paper-title-an-artificial-emg-generation-model-based-on-signal-dependent-noise-and-related-application-to-motion-classification">An Artificial EMG Generation Model Based on Signal-dependent Noise and Related Application to Motion Classification</h3><div class="mb-2"><div class="flex flex-wrap gap-1"><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">Akira Furui</span><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">Hideaki Hayashi</span><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">...</span><button class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-blue-600 hover:bg-gray-100 border border-gray-100 transition-colors">+3 more</button></div></div><div class="flex items-center gap-2 text-sm mt-1"><div class="relative inline-flex items-center group/venue"><span class="line-clamp-1 text-gray-500">PLOS ONE</span></div><span class="text-gray-400">•</span><span class="text-gray-500">2017</span></div></div></div><div class="relative z-20 p-4 pt-0">  <div class="space-y-2.5"><div><button class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800 mb-2 cursor-pointer hover:bg-gray-100 px-2 py-1 rounded-md transition-colors"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-down"><path d="m6 9 6 6 6-6"></path></svg>Abstract</button></div><div class="flex flex-wrap gap-1.5"><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">EMG</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Motion Recognition</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Probabilistic Model</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Data Generation</div></div><div><button class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800">Show<!-- --> BibTeX</button></div><div class="flex flex-wrap gap-4 mt-3"><div class="flex items-center gap-1 text-sm text-blue-600 hover:text-blue-800 cursor-pointer" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:R353or6:" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-file-text"><path d="M15 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V7Z"></path><path d="M14 2v4a2 2 0 0 0 2 2h4"></path><path d="M10 9H8"></path><path d="M16 13H8"></path><path d="M16 17H8"></path></svg>PDF</div><a href="https://doi.org/10.1371/journal.pone.0180112" class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800" target="_blank" rel="noopener noreferrer"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-external-link flex-shrink-0"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg>DOI</a></div></div></div></div><div class="rounded-lg border text-card-foreground shadow-sm group relative hover:shadow-lg transition-all duration-300 bg-white overflow-hidden" role="article" aria-labelledby="paper-title-variance-distribution-analysis-of-surface-emg-signals-based-on-marginal-maximum-likelihood-estimation"><div class="aspect-video overflow-hidden relative"><img alt="Cover image for Variance distribution analysis of surface EMG signals based on marginal maximum likelihood estimation" loading="lazy" decoding="async" data-nimg="fill" class="transition-transform duration-300 group-hover:scale-105" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;color:transparent" src="https://drive.google.com/thumbnail?id=1uSHojYQ3-Gmk8EGXM1XksvSaBcyJYdlY&amp;sz=w2048"/></div><div class="flex flex-col space-y-1.5 relative z-20 p-4"><div class="flex items-center gap-2 mb-2"><span class="text-lg font-medium text-gray-600">2017</span><span class="
      inline-flex items-center px-2.5 py-1 rounded-full text-sm font-medium 
      text-emerald-600 bg-emerald-50 border-emerald-200 border
      transition-colors
    ">International Conf.</span></div><div><h3 class="tracking-tight text-base font-bold mb-1" id="paper-title-variance-distribution-analysis-of-surface-emg-signals-based-on-marginal-maximum-likelihood-estimation">Variance distribution analysis of surface EMG signals based on marginal maximum likelihood estimation</h3><div class="mb-2"><div class="flex flex-wrap gap-1"><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">Akira Furui</span><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">Hideaki Hayashi</span><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">...</span><button class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-blue-600 hover:bg-gray-100 border border-gray-100 transition-colors">+2 more</button></div></div><div class="flex items-center gap-2 text-sm mt-1"><div class="relative inline-flex items-center group/venue"><span class="line-clamp-1 text-gray-500">EMBC</span></div><span class="text-gray-400">•</span><span class="text-gray-500">2017</span></div></div></div><div class="relative z-20 p-4 pt-0">  <div class="space-y-2.5"><div><button class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800 mb-2 cursor-pointer hover:bg-gray-100 px-2 py-1 rounded-md transition-colors"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-down"><path d="m6 9 6 6 6-6"></path></svg>Abstract</button></div><div class="flex flex-wrap gap-1.5"><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">EMG</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Probabilistic Model</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Movement Analysis</div></div><div><button class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800">Show<!-- --> BibTeX</button></div><div class="flex flex-wrap gap-4 mt-3"><a href="https://doi.org/10.1109/EMBC.2017.8037368" class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800" target="_blank" rel="noopener noreferrer"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-external-link flex-shrink-0"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg>DOI</a></div></div></div></div><div class="rounded-lg border text-card-foreground shadow-sm group relative hover:shadow-lg transition-all duration-300 bg-white overflow-hidden" role="article" aria-labelledby="paper-title-virtual-restoration-of-down-sampled-emg-signals-using-a-stochastic-model"><div class="absolute inset-0 cursor-pointer z-10" role="button" tabindex="0" aria-label="View PDF: Virtual Restoration of Down-sampled EMG Signals Using a Stochastic Model"></div><div class="aspect-video overflow-hidden relative"><img alt="Cover image for Virtual Restoration of Down-sampled EMG Signals Using a Stochastic Model" loading="lazy" decoding="async" data-nimg="fill" class="transition-transform duration-300 group-hover:scale-105" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;color:transparent" src="https://drive.google.com/thumbnail?id=1iIeeNJaL5j_TKaNB3o07rQkHm5ynrjGv&amp;sz=w2048"/><div class="absolute inset-0 bg-black/50 opacity-0 group-hover:opacity-100 transition-opacity duration-300 flex items-center justify-center"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-file-text w-8 h-8 text-white"><path d="M15 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V7Z"></path><path d="M14 2v4a2 2 0 0 0 2 2h4"></path><path d="M10 9H8"></path><path d="M16 13H8"></path><path d="M16 17H8"></path></svg></div></div><div class="flex flex-col space-y-1.5 relative z-20 p-4"><div class="flex items-center gap-2 mb-2"><span class="text-lg font-medium text-gray-600">2017</span><span class="
      inline-flex items-center px-2.5 py-1 rounded-full text-sm font-medium 
      text-emerald-600 bg-emerald-50 border-emerald-200 border
      transition-colors
    ">International Conf.</span></div><div><h3 class="tracking-tight text-base font-bold mb-1 cursor-pointer hover:text-blue-600 transition-colors" id="paper-title-virtual-restoration-of-down-sampled-emg-signals-using-a-stochastic-model">Virtual Restoration of Down-sampled EMG Signals Using a Stochastic Model</h3><div class="mb-2"><div class="flex flex-wrap gap-1"><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">Akira Furui</span><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">Hideaki Hayashi</span><span class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-gray-600 border border-gray-100">...</span><button class="inline-flex items-center px-2 py-0.5 rounded-md text-sm bg-gray-50 text-blue-600 hover:bg-gray-100 border border-gray-100 transition-colors">+5 more</button></div></div><div class="flex items-center gap-2 text-sm mt-1"><div class="relative inline-flex items-center group/venue"><span class="line-clamp-1 text-gray-500">i-CREATe</span></div><span class="text-gray-400">•</span><span class="text-gray-500">2017</span></div></div></div><div class="relative z-20 p-4 pt-0">  <div class="space-y-2.5"><div><button class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800 mb-2 cursor-pointer hover:bg-gray-100 px-2 py-1 rounded-md transition-colors"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-down"><path d="m6 9 6 6 6-6"></path></svg>Abstract</button></div><div class="flex flex-wrap gap-1.5"><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">EMG</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Probabilistic Model</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Data Generation</div></div><div><button class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800">Show<!-- --> BibTeX</button></div><div class="flex flex-wrap gap-4 mt-3"><div class="flex items-center gap-1 text-sm text-blue-600 hover:text-blue-800 cursor-pointer" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:R353sr6:" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-file-text"><path d="M15 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V7Z"></path><path d="M14 2v4a2 2 0 0 0 2 2h4"></path><path d="M10 9H8"></path><path d="M16 13H8"></path><path d="M16 17H8"></path></svg>PDF</div><a href="https://doi.org/10.5555/3162110.3162141" class="flex items-center gap-1 text-sm text-gray-600 hover:text-gray-800" target="_blank" rel="noopener noreferrer"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-external-link flex-shrink-0"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg>DOI</a></div></div></div></div></div></div></div><footer class="mt-12 py-6 border-t border-gray-200"><div class="max-w-7xl mx-auto px-4"><div class="flex flex-col items-center text-center space-y-4"><p class="text-sm text-gray-500 max-w-2xl">The papers in this repository are provided in their accepted versions in accordance with the permission conditions of each publisher. Please refer to the respective publisher&#x27;s policies for detailed terms of use.</p><div class="w-full border-t border-gray-100"></div><p class="text-sm text-gray-400">Intelligent Biosignal Informatics Laboratory, Graduate School of Advanced Science and Engineering, Hiroshima University</p></div></div></footer></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"papers":[{"title":"Variance distribution analysis of surface EMG signals based on marginal maximum likelihood estimation","authors":["Akira Furui","Hideaki Hayashi","Yuichi Kurita","Toshio Tsuji"],"venue":"Proceedings of 39th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC2017)","venueShort":"EMBC","year":2017,"pages":"2514--2517","pdfUrl":"","codeUrl":"","doi":"10.1109/EMBC.2017.8037368","tags":["EMG","Probabilistic Model","Movement Analysis"],"type":"international","coverImage":"https://drive.google.com/thumbnail?id=1uSHojYQ3-Gmk8EGXM1XksvSaBcyJYdlY\u0026sz=w2048","abstract":"This paper describes the estimation and analysis of variance distribution of surface electromyogram (EMG) signals based on a stochastic EMG model. With the assumption that EMG signals at a certain time follow Gaussian distribution, their variance is handled as a random variable that follows inverse gamma distribution, and noise superimposed onto this variance can be expressed accordingly. The paper proposes variance distribution estimation based on marginal likelihood maximization of EMG signals. A simulation experiment using artificially generated signals to verify its accuracy indicated that the method can estimate variance distribution with high accuracy for a wide range of variance distribution shaping. Analysis of variance distribution using measured EMG signals revealed the relationship between muscle force and variance distribution involving signal-dependent noise."},{"title":"Virtual Restoration of Down-sampled EMG Signals Using a Stochastic Model","authors":["Akira Furui","Hideaki Hayashi","Takaei Kihara","Takahiro Konishi","Yusuke Yoshida","Yuichi Kurita","Toshio Tsuji"],"venue":"Proceedings of the 11th International Convention on Rehabilitation Engineering and Assistive Technology (i-CREATe2017)","venueShort":"i-CREATe","year":2017,"pages":"PP5-3","pdfUrl":"https://drive.google.com/file/d/1Ozq0VLqbctEqpi0rwuvYlJqGBc779H3i/view?usp=sharing","codeUrl":"","doi":"10.5555/3162110.3162141","tags":["EMG","Probabilistic Model","Data Generation"],"type":"international","coverImage":"https://drive.google.com/thumbnail?id=1iIeeNJaL5j_TKaNB3o07rQkHm5ynrjGv\u0026sz=w2048","abstract":"This paper proposes a virtual restoration method of down-sampled electromyogram (EMG) signals for low-traffic wireless communication. In this approach, EMG signals measured from a wireless EMG sensor are rectified, smoothed, and transmitted with down-sampling. On the receiving side, artificial EMG signals reproducing the characteristics of the measured signals can be generated in real time based on a stochastic EMG generation model. The experiments conducted to verify restoration accuracy and applicability to measured signals indicated that the proposed method reproduces the characteristics of measured signals with high accuracy and low delay, although the amount of information transmitted is drastically reduced."},{"title":"An Artificial EMG Generation Model Based on Signal-dependent Noise and Related Application to Motion Classification","authors":["Akira Furui","Hideaki Hayashi","Go Nakamura","Takaaki Chin","Toshio Tsuji"],"venue":"PLOS ONE","year":2017,"pages":"e0180112","pdfUrl":"https://drive.google.com/file/d/10xC-toAmoSY1oVbYRERoHFHwY_p1uOTk/view?usp=sharing","codeUrl":"","doi":"10.1371/journal.pone.0180112","volume":"12","number":"6","tags":["EMG","Motion Recognition","Probabilistic Model","Data Generation"],"type":"journal","coverImage":"https://drive.google.com/thumbnail?id=19few4HU18Aq-S-pJhmEErLR1osGWaDnA\u0026sz=w2048","abstract":"This paper proposes an artificial electromyogram (EMG) signal generation model based on signal-dependent noise, which has been ignored in existing methods, by introducing the stochastic construction of the EMG signals. In the proposed model, an EMG signal variance value is first generated from a probability distribution with a shape determined by a commanded muscle force and signal-dependent noise. Artificial EMG signals are then generated from the associated Gaussian distribution with a zero mean and the generated variance. This facilitates representation of artificial EMG signals with signal-dependent noise superimposed according to the muscle activation levels. The frequency characteristics of the EMG signals are also simulated via a shaping filter with parameters determined by an autoregressive model. An estimation method to determine EMG variance distribution using rectified and smoothed EMG signals, thereby allowing model parameter estimation with a small number of samples, is also incorporated in the proposed model. Moreover, the prediction of variance distribution with strong muscle contraction from EMG signals with low muscle contraction and related artificial EMG generation are also described. The results of experiments conducted, in which the reproduction capability of the proposed model was evaluated through comparison with measured EMG signals in terms of amplitude, frequency content, and EMG distribution demonstrate that the proposed model can reproduce the features of measured EMG signals. Further, utilizing the generated EMG signals as training data for a neural network resulted in the classification of upper limb motion with a higher precision than by learning from only measured EMG signals. This indicates that the proposed model is also applicable to motion classification."},{"title":"An EMG pattern classification method based on a mixture of variance distribution models","authors":["Akira Furui","Hideaki Hayashi","Toshio Tsuji"],"venue":"Proceedings of 40th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC2018)","venueShort":"EMBC","year":2018,"pages":"5216--5219","pdfUrl":"","codeUrl":"","doi":"10.1109/EMBC.2018.8513446","tags":["EMG","Probabilistic Model","Motion Recognition"],"type":"international","coverImage":"https://drive.google.com/thumbnail?id=1wbG1uBFMkckNMouY-NE276_Ui2cX56kg\u0026sz=w2048","abstract":"This paper proposes an electromyogram (EMG) pattern classification method based on a mixture of variance distribution models. A variance distribution model is a stochastic model of raw surface EMG signals in which the EMG variance is taken as a random variable, allowing the representation of uncertainty in the variance. In this paper, we extend the variance distribution model to the multidimensional case and enhance its flexibility for multichannel and processed EMG signals. The enhanced model enables the accurate classification of EMG patterns while considering the uncertainty in the EMG variance. The robustness and applicability of the proposed method are demonstrated through a simulation experiment using artificially generated data and EMG classification experiments using two real datasets."},{"title":"Muscle Fatigue Analysis by Using a Scale Mixture-based Stochastic Model of Surface EMG Signals","authors":["Akira Furui","Toshio Tsuji"],"venue":"Proceedings of 41st Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC2019)","venueShort":"EMBC","year":2019,"pages":"1948--1951","pdfUrl":"https://drive.google.com/file/d/1oybrJ6lMnoZQ6IL99jCqj0pw5TbY_xMy/view?usp=sharing","codeUrl":"","doi":"10.1109/EMBC.2019.8856348","tags":["EMG","Probabilistic Model","Movement Analysis"],"type":"international","coverImage":"https://drive.google.com/thumbnail?id=1S2DW4BX69pzKq22PvFV2VweNRdyh0sE8\u0026sz=w2048","abstract":"This paper presents the estimation and analysis of surface electromyogram (EMG) signals during fatiguing contractions based on a stochastic EMG model. In the model, the probability distribution of EMG signals is assumed to be a mixture of Gaussians with the same mean but different variances, facilitating the representation of the variance distribution of EMG signals. The paper proposes a continuous estimation method for variance distribution parameters using a sliding window, enabling the evaluation of the time-varying stochastic properties of EMG signals. Estimation experiments were conducted on six healthy young adults to analyze changes in EMG variance distribution with the progression of muscle fatigue. The results reveal the linear and nonlinear relationships between muscle fatigue and variance distribution parameters."},{"title":"A Scale Mixture-based Stochastic Model of Surface EMG Signals with Variable Variances","authors":["Akira Furui","Hideaki Hayashi","Toshio Tsuji"],"venue":"IEEE Transactions on Biomedical Engineering","venueShort":"IEEE TBME","year":2019,"pages":"2780-2788","pdfUrl":"https://drive.google.com/file/d/1T2nT0IZUqT_gTnddT4ZKzX5BFBM_0hz1/view?usp=sharing","codeUrl":"","doi":"10.1109/TBME.2019.2895683","volume":"66","number":"10","tags":["EMG","Machine Learning","Motion Recognition","Probabilistic Model"],"type":"journal","coverImage":"https://drive.google.com/thumbnail?id=1k3gGkdd7_M6X-85WEXPRg7xfVBnxs6NH\u0026sz=w2048","abstract":"Surface electromyogram (EMG) signals have typically been assumed to follow a Gaussian distribution. However, the presence of non-Gaussian signals associated with muscle activity has been reported in recent studies, and there is no general model of the distribution of EMG signals that can explain both non-Gaussian and Gaussian distributions within a unified scheme. Methods: In this paper, we describe the formulation of a non-Gaussian EMG model based on a scale mixture distribution. In the model, an EMG signal at a certain time follows a Gaussian distribution, and its variance is handled as a random variable that follows an inverse gamma distribution. Accordingly, the probability distribution of EMG signals is assumed to be a mixture of Gaussians with the same mean but different variances. The EMG variance distribution is estimated via marginal likelihood maximization. Results: Experiments involving nine participants revealed that the proposed model provides a better fit to recorded EMG signals than conventional EMG models. It was also shown that variance distribution parameters may reflect underlying motor unit activity. Conclusion: This study proposed a scale mixture distribution-based stochastic EMG model capable of representing changes in non-Gaussianity associated with muscle activity. A series of experiments demonstrated the validity of the model and highlighted the relationship between the variance distribution and muscle force. Significance: The proposed model helps to clarify conventional wisdom regarding the probability distribution of surface EMG signals within a unified scheme."},{"title":"A Myoelectric Prosthetic Hand with Muscle Synergy-based Motion Determination and Impedance Model-based Biomimetic Control","authors":["Akira Furui","Shintaro Eto","Kosuke Nakagaki","Kyohei Shimada","Go Nakamura","Akito Masuda","Takaaki Chin","Toshio Tsuji"],"venue":"Science Robotics","year":2019,"pages":"eaaw6339","pdfUrl":"https://drive.google.com/file/d/1eWL5u8hkO_WplLpT9lfVLaOiKBUM8slE/view?usp=sharing","codeUrl":"","doi":"10.1126/scirobotics.aaw6339","volume":"4","number":"31","tags":["EMG","Machine Learning","Motion Recognition","Prosthetic Hand"],"type":"journal","coverImage":"https://drive.google.com/thumbnail?id=1EIhl_fv9ZbVfg_5ga9QozW8nhTPVP4Bx\u0026sz=w2048","abstract":"Prosthetic hands are prescribed to patients who have suffered an amputation of the upper limb due to an accident or a disease. This is done to allow patients to regain functionality of their lost hands. Myoelectric prosthetic hands were found to have the possibility of implementing intuitive controls based on operator’s electromyogram (EMG) signals. These controls have been extensively studied and developed. In recent years, development costs and maintainability of prosthetic hands have been improved through 3D printing technology. However, no previous studies have realized the advantages of EMG-based classification of multiple finger movements in conjunction with the introduction of advanced control mechanisms based on human motion. This paper proposes a 3D-printed myoelectric prosthetic hand and an accompanying control system. The muscle synergy-based motion determination method and biomimetic impedance control are introduced in the proposed system, enabling the classification of unlearned combined motions and smooth and intuitive finger movements of the prosthetic hand. We evaluate the proposed system through operational experiments performed on six healthy participants and an upper-limb amputee participant. The experimental results demonstrate that our prosthetic hand system can successfully classify both learned single motions and unlearned combined motions from EMG signals with a high degree of accuracy. Furthermore, applications to real-world uses of prosthetic hands are demonstrated through control tasks conducted by the amputee participant."},{"title":"Does the variance of surface EMG signals during isometric contractions follow an inverse gamma distribution?","authors":["Akira Furui","Toshio Tsuji"],"venue":"Proceedings of 42nd Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC2020)","venueShort":"EMBC","year":2020,"pages":"3118--3121","pdfUrl":"https://drive.google.com/file/d/1RFjvYM-wcktt2eR54VZVNWiQgsaQJHDB/view?usp=sharing","codeUrl":"","doi":"10.1109/EMBC44109.2020.9176102","tags":["EMG","Probabilistic Model","Movement Analysis"],"type":"international","coverImage":"https://drive.google.com/thumbnail?id=10cTjf3ANNJOseGBuC81-yvjMyaxZU7E1\u0026sz=w2048","abstract":"In this paper, the validity of the stochastic model-based variance distribution of surface electromyogram (EMG) signals during isometric contraction is investigated. In the model, the EMG variance is considered as a random variable following an inverse gamma distribution, thereby allowing the representation of variations in the variance. This inverse gamma-based model for the EMG variance is experimentally validated through comparison with the empirical distribution of variances. The difference between the model distribution and the empirical distribution is quantified using the Kullback-Leibler divergence. Additionally, regression analysis is conducted between the model parameters and the statistics calculated from the empirical distribution of EMG variances. Experimental results showed that the inverse gamma-based model is potentially suitable and that its parameters can be used to evaluate the stochastic properties of the EMG variance."},{"title":"Spatiotemporal Parameterization of Human Reaching Movements Based on Time Base Generator","authors":["Masanobu Kittaka","Akira Furui","Hiroto Sakai","Pietro Morasso","Toshio Tsuji"],"venue":"IEEE Access","year":2020,"pages":"104944-104955","pdfUrl":"https://drive.google.com/file/d/14mKGNDJGS7V0QgdcDEj-t6QXbBuRcDCF/view?usp=sharing","codeUrl":"","doi":"10.1109/ACCESS.2020.3000273","volume":"8","number":"","tags":["Movement Analysis","Reaching Movement"],"type":"journal","coverImage":"https://drive.google.com/thumbnail?id=1pf0mB0LryYb8jVW977_NhnBNXA5MH6O1\u0026sz=w2048","abstract":"Surface electromyogram (EMG) signals have typically been assumed to follow a Gaussian distribution. However, the presence of non-Gaussian signals associated with muscle activity has been reported in recent studies, and there is no general model of the distribution of EMG signals that can explain both non-Gaussian and Gaussian distributions within a unified scheme. Methods: In this paper, we describe the formulation of a non-Gaussian EMG model based on a scale mixture distribution. In the model, an EMG signal at a certain time follows a Gaussian distribution, and its variance is handled as a random variable that follows an inverse gamma distribution. Accordingly, the probability distribution of EMG signals is assumed to be a mixture of Gaussians with the same mean but different variances. The EMG variance distribution is estimated via marginal likelihood maximization. Results: Experiments involving nine participants revealed that the proposed model provides a better fit to recorded EMG signals than conventional EMG models. It was also shown that variance distribution parameters may reflect underlying motor unit activity. Conclusion: This study proposed a scale mixture distribution-based stochastic EMG model capable of representing changes in non-Gaussianity associated with muscle activity. A series of experiments demonstrated the validity of the model and highlighted the relationship between the variance distribution and muscle force. Significance: The proposed model helps to clarify conventional wisdom regarding the probability distribution of surface EMG signals within a unified scheme."},{"title":"A Time-Series Scale Mixture Model of EEG with a Hidden Markov Structure for Epileptic Seizure Detection","authors":["Akira Furui","Tomoyuki Akiyama","Toshio Tsuji"],"venue":"Proceedings of 43rd Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC2021)","venueShort":"EMBC","year":2021,"pages":"5832--5836","pdfUrl":"https://drive.google.com/file/d/1mGs3Mb3q7Gyv4mEqkh_6XGgYbz0BmTHO/view?usp=sharing","codeUrl":"","doi":"10.1109/EMBC46164.2021.9630840","tags":["EEG","Epileptic Seizure Detection","Probabilistic Model","Time-series Analysis"],"type":"international","coverImage":"https://drive.google.com/thumbnail?id=1CP_U8s_VRPv1_WJ_Q-vzpuGasRAscTpw\u0026sz=w2048","abstract":"In this paper, we propose a time-series stochastic model based on a scale mixture distribution with Markov transitions to detect epileptic seizures in electroencephalography (EEG). In the proposed model, an EEG signal at each time point is assumed to be a random variable following a Gaussian distribution. The covariance matrix of the Gaussian distribution is weighted with a latent scale parameter, which is also a random variable, resulting in the stochastic fluctuations of covariances. By introducing a latent state variable with a Markov chain in the background of this stochastic relationship, time-series changes in the distribution of latent scale parameters can be represented according to the state of epileptic seizures. In an experiment, we evaluated the performance of the proposed model for seizure detection using EEGs with multiple frequency bands decomposed from a clinical dataset. The results demonstrated that the proposed model can detect seizures with high sensitivity and outperformed several baselines."},{"title":"EMG pattern recognition via Bayesian inference with scale mixture-based stochastic generative models","authors":["Akira Furui","Takuya Igaue","Toshio Tsuji"],"venue":"Expert Systems with Applications","year":2021,"pages":"115644","pdfUrl":"https://drive.google.com/file/d/1sdNTf3d-ozxriQs4FKr439fuQqfyZJ-k/view?usp=sharing","codeUrl":"","doi":"10.1016/j.eswa.2021.115644","volume":"185","tags":["EMG","Machine Learning","Motion Recognition","Bayesian Model"],"type":"journal","coverImage":"https://drive.google.com/thumbnail?id=1Bld1lBrGC7cNdSExRXlFS1QTk9QmaF0B\u0026sz=w2048","abstract":"Electromyogram (EMG) has been utilized to interface signals for prosthetic hands and information devices owing to its ability to reflect human motion intentions. Although various EMG classification methods have been introduced into EMG-based control systems, they do not fully consider the stochastic characteristics of EMG signals. This paper proposes an EMG pattern classification method incorporating a scale mixture-based generative model. A scale mixture model is a stochastic EMG model in which the EMG variance is considered as a random variable, enabling the representation of uncertainty in the variance. This model is extended in this study and utilized for EMG pattern classification. The proposed method is trained by variational Bayesian learning, thereby allowing the automatic determination of the model complexity. Furthermore, to optimize the hyperparameters of the proposed method with a partial discriminative approach, a mutual information-based determination method is introduced. Simulation and EMG analysis experiments demonstrated the relationship between the hyperparameters and classification accuracy of the proposed method as well as the validity of the proposed method. The comparison using public EMG datasets revealed that the proposed method outperformed the various conventional classifiers. These results indicated the validity of the proposed method and its applicability to EMG-based control systems. In EMG pattern recognition, a classifier based on a generative model that reflects the stochastic characteristics of EMG signals can outperform the conventional general-purpose classifier."},{"title":"Biomimetic Control of Myoelectric Prosthetic Hand Based on a Lambda-type Muscle Model","authors":["Akira Furui","Kosuke Nakagaki","Toshio Tsuji"],"venue":"Proceedings of 2021 IEEE International Conference on Robotics and Automation (ICRA)","venueShort":"ICRA","year":2021,"pages":"10484-10490","pdfUrl":"https://drive.google.com/file/d/19CtXnDkbLw41ba-XT7BlIcVDWEVbX48H/view?usp=sharing","codeUrl":"","doi":"10.1109/ICRA48506.2021.9561288","tags":["EMG","Prosthetic Hand","Biomimetic Control"],"type":"international","coverImage":"https://drive.google.com/thumbnail?id=1xEcbFgxXaqKxoZHQbTPS0KHnOU6muq47\u0026sz=w2048","abstract":"Myoelectric prosthetic hands are intended to re-place the function of the amputee’s lost arm. Therefore, developing robotic prosthetics that can mimic not only the appearance and functionality of humans but also characteristics unique to human movements is paramount. This paper proposes a novel biomimetic control method for myoelectric prosthetic hands integrating the impedance model with the concept of the λ-type muscle model. According to the state of the muscle, the proposed method can dynamically control the joint equilibrium position, and can maintain the joint angle naturally during muscle relaxation. The experimental results, based on comparison with the actual human joint angles, suggest that the proposed method has a better correlation with the actual human motion than the conventional methods. Additionally, the control experiments showed that the proposed method could achieve a natural prosthetic hand movement similar to that of a human, thereby allowing voluntary hand movements."},{"title":"Non-Gaussianity Detection of EEG Signals Based on a Multivariate Scale Mixture Model for Diagnosis of Epileptic Seizures","authors":["Akira Furui","Ryota Onishi","Akihito Takeuchi","Tomoyuki Akiyama","Toshio Tsuji"],"venue":"IEEE Transactions on Biomedical Engineering","venueShort":"IEEE TBME","year":2021,"pages":"515-525","pdfUrl":"https://drive.google.com/file/d/1M-3gaJAIt7KqpccLW-PQUk9ZLq5fItLg/view?usp=sharing","codeUrl":"","doi":"10.1109/TBME.2020.3006246","volume":"68","number":"2","tags":["EEG","Epileptic Seizure Detection","Probabilistic Model"],"type":"journal","coverImage":"https://drive.google.com/thumbnail?id=1SpUFpCJiiJoSdxtW0Se2hPg2RjbVSGgD\u0026sz=w2048","abstract":"Objective: The detection of epileptic seizures from scalp electroencephalogram (EEG) signals can facilitate early diagnosis and treatment. Previous studies suggested that the Gaussianity of EEG distributions changes depending on the presence or absence of seizures; however, no general EEG signal models can explain such changes in distributions within a unified scheme. Methods: This article describes the formulation of a stochastic EEG model based on a multivariate scale mixture distribution that can represent changes in non-Gaussianity caused by stochastic fluctuations in EEG. In addition, we propose an EEG analysis method by combining the model with a filter bank and introduce a feature representing the non-Gaussianity latent in each EEG frequency band. Results: We applied the proposed method to multichannel EEG data from twenty patients with focal epilepsy. The results showed a significant increase in the proposed feature during epileptic seizures, particularly in the high-frequency band. The feature calculated in the high-frequency band allowed highly accurate classification of seizure and non-seizure segments [area under the receiver operating characteristic curve (AUC) = 0.881] using only a simple threshold. Conclusion: This article proposed a multivariate scale mixture distribution-based stochastic EEG model capable of representing non-Gaussianity associated with epileptic seizures. Experiments using simulated and real EEG data demonstrated the validity of the model and its applicability to epileptic seizure detection. Significance: The stochastic fluctuations of EEG quantified by the proposed model can help detect epileptic seizures with high accuracy."},{"title":"Prediction of autistic tendencies at 18 months of age via markerless video analysis of spontaneous body movements in 4-month-old infants","authors":["Hirokazu Doi","Naoya Iijima","Akira Furui","Zu Soh","Rikuya Yonei","Kazuyuki Shinohara","Mayuko Iriguchi","Koji Shimatani","Toshio Tsuji"],"venue":"Scientific Reports","year":2022,"pages":"18045","pdfUrl":"https://drive.google.com/file/d/1tiwbgFdmFF_qCdsShIbYxYwgfbSZ3aPH/view?usp=sharing","codeUrl":"","doi":"10.1038/s41598-022-21308-y","volume":"12","tags":["Medical Image/Video","Infants","Movement Analysis","Machine Learning"],"type":"journal","coverImage":"https://drive.google.com/thumbnail?id=1m4V0_WBlcp2tvKC3zmvoyCM4dX2yyY1a\u0026sz=w2048","abstract":"Early intervention is now considered the core treatment strategy for autism spectrum disorders (ASD). Thus, it is of significant clinical importance to establish a screening tool for the early detection of ASD in infants. To achieve this goal, in a longitudinal design, we analyzed spontaneous bodily movements of 4-month-old infants from general population and assessed their ASD-like behaviors at 18 months of age. A total of 26 movement features were calculated from video-recorded bodily movements of infants at 4 months of age. Their risk of ASD was assessed at 18 months of age with the Modified Checklist for Autism in Toddlerhood, a widely used screening questionnaire. Infants at high risk for ASD at 18 months of age exhibited less rhythmic and weaker bodily movement patterns at 4 months of age than low-risk infants. When the observed bodily movement patterns were submitted to a machine learning-based analysis, linear and non-linear classifiers successfully predicted ASD-like behavior at 18 months of age based on the bodily movement patterns at 4 months of age, at the level acceptable for practical use. This study analyzed the relationship between spontaneous bodily movements at 4 months of age and the ASD risk at 18 months of age. Experimental results suggested the utility of the proposed method for the early screening of infants at risk for ASD. We revealed that the signs of ASD risk could be detected as early as 4 months after birth, by focusing on the infant’s spontaneous bodily movements."},{"title":"Automated Classification of General Movements in Infants Using Two-stream Spatiotemporal Fusion Network","authors":["Yuki Hashimoto","Akira Furui","Koji Shimatani","Maura Casadio","Paolo Moretti","Pietro Morasso","Toshio Tsuji"],"venue":"Proceedings of 25th International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI2022)","venueShort":"MICCAI","year":2022,"pages":"753-762","pdfUrl":"https://drive.google.com/file/d/11SUyZkbyxRfYdiuVcZxAMzYWevHB_0HU/view?usp=sharing","codeUrl":"https://github.com/hashyuki/two-stream-gma","doi":"10.1007/978-3-031-16434-7_72","tags":["Medical Image/Video","Movement Analysis","Infants","Deep Learning"],"type":"international","coverImage":"https://drive.google.com/thumbnail?id=1_It8dINmyZ_AU6T_mmtHnBDtdCRCY_Et\u0026sz=w2048","abstract":"The assessment of general movements (GMs) in infants is a useful tool in the early diagnosis of neurodevelopmental disorders. However, its evaluation in clinical practice relies on visual inspection by experts, and an automated solution is eagerly awaited. Recently, video-based GMs classification has attracted attention, but this approach would be strongly affected by irrelevant information, such as background clutter in the video. Furthermore, for reliability, it is necessary to properly extract the spatiotemporal features of infants during GMs. In this study, we propose an automated GMs classification method, which consists of preprocessing networks that remove unnecessary background information from GMs videos and adjust the infant's body position, and a subsequent motion classification network based on a two-stream structure. The proposed method can efficiently extract the essential spatiotemporal features for GMs classification while preventing overfitting to irrelevant information for different recording environments. We validated the proposed method using videos obtained from 100 infants. The experimental results demonstrate that the proposed method outperforms several baseline models and the existing methods."},{"title":"Sleep EEG Analysis Based on a Scale Mixture Model and Spindle Detection","authors":["Miyari Hatamoto","Akira Furui","Keiko Ogawa","Toshio Tsuji"],"venue":"Proceedings of the 2022 IEEE/SICE International Symposium on System Integration (SII2022)","venueShort":"SII","year":2022,"pages":"887-892","pdfUrl":"https://drive.google.com/file/d/1U_CdBqRTPcBWuJ9UhEUjLff7C993SDRy/view?usp=sharing","codeUrl":"","doi":"10.1109/SII52469.2022.9708856","tags":["EEG","Sleep Analysis","Probabilistic Model"],"type":"international","coverImage":"https://drive.google.com/thumbnail?id=1F0Mr_8CTaoEjv1NgvJ-VAAKXWJRsL9wp\u0026sz=w2048","abstract":"This paper presents analysis of sleep electroen-cephalogram (EEG) based on a scale mixture model. In the scale mixture model, the EEG signal is assumed to be a random variable that follows a infinite mixture of Gaussian distributions with the same mean and different covariance matrices, thereby allowing the representation of the stochastic fluctuation of the EEG amplitude. First, a sleep EEG analysis method was proposed by combining the scale mixture model with band-pass filters and a sliding window, thereby allowing the time-series estimation of the model parameters in a specific frequency band. Then, in experiments, we analyzed the EEG signals during rapid eye movement (REM) sleep and sleep stage II using the proposed analysis method. The results showed that the proposed method captures the characteristic changes in the amplitude distribution of the EEG depending on the sleep stage. Furthermore, we focused on sleep spindles in sleep stage II, which are distinctive waves in sleep EEG, and verified their detectability by machine learning using the features defined by the proposed method as input."},{"title":"ベイズ逐次学習に基づく筋電位パターンの適応的分類","authors":["米田 清太朗","古居 彬"],"venue":"第24回計測自動制御学会システムインテグレーション部門講演会（SI2022）","venueShort":"SI","year":2022,"month":12,"pages":"363-368","pdfUrl":"https://drive.google.com/file/d/15iuwbTor869G-9bWMizivXTukd_BiEdl/view?usp=sharing","tags":["EMG","Bayesian Model","Machine Learning","Motion Recognition"],"type":"domestic","coverImage":"https://drive.google.com/thumbnail?id=1UonJGSUmmfhVc-4OTw5SpzJmvgLmciIO\u0026sz=w2048","abstract":"筋電位信号からヒトの動作を識別することで，筋電義手など様々な機器の操作が可能である．しかしながら，従来手法の多くは静的なパターン分類モデルを採用しているため，動作イメージの変化や筋疲労などによる経時的な信号特性の変化に対応できなかった．そこで本稿では，ベイズ逐次学習による適応的な筋電位パターン分類法を提案する．提案法では，ガウス分布に基づくベイズ分類モデルを用いて動作クラスの予測とその不確実性の推定を行う．そして，確信度の高いデータに対して逐次的にモデルの事後分布を更新することで，適応的な動作識別を実現する.実験では,健常成人男性３名から得られた筋電位信号を用いて提案法の有効性を検証した."},{"title":"Evaluating Classifier Confidence for Surface EMG Pattern Recognition","authors":["Akira Furui"],"venue":"Proceedings of 45th Annual International Conference of the IEEE Engineering in Medicine and Biology Society","venueShort":"EMBC","year":2023,"pages":"3310-3315","pdfUrl":"https://drive.google.com/file/d/1d9TX3PWIDtYr2g6UeyRy0KGk7jL11iE_/view?usp=sharing","codeUrl":"","arxivUrl":"https://arxiv.org/abs/2304.05898","doi":"10.1109/EMBC40787.2023.10340977","tags":["EMG","Machine Learning","Motion Recognition"],"type":"international","coverImage":"https://drive.google.com/thumbnail?id=1WLlfs_rA54oyNMYrIaiTDq8ucIn9eeQU\u0026sz=w2048","abstract":"Surface electromyogram (EMG) can be employed as an interface signal for various devices and software via pattern recognition. In EMG-based pattern recognition, the classifier should not only be accurate, but also output an appropriate confidence (i.e., probability of correctness) for its prediction. If the confidence accurately reflects the likelihood of true correctness, then it will be useful in various application tasks, such as motion rejection and online adaptation. The aim of this paper is to identify the types of classifiers that provide higher accuracy and better confidence in EMG pattern recognition. We evaluate the performance of various discriminative and generative classifiers on four EMG datasets, both visually and quantitatively. The analysis results show that while a discriminative classifier based on a deep neural network exhibits high accuracy, it outputs a confidence that differs from true probabilities. By contrast, a scale mixture model-based classifier, which is a generative classifier that can account for uncertainty in EMG variance, exhibits superior performance in terms of both accuracy and confidence."},{"title":"Mixupを利用した筋電位信号の擬似データ生成と複合動作の識別","authors":["矢沢 樹","古居 彬"],"venue":"第24回計測自動制御学会システムインテグレーション部門講演会（SI2023）","venueShort":"SI","year":2023,"month":12,"pages":"363-368","pdfUrl":"https://drive.google.com/file/d/1cX6Pg7jFCljllDY1RlUnI3Yl9YahSZY1/view?usp=sharing","tags":["EMG","Machine Learning","Motion Recognition","Data Generation"],"type":"domestic","coverImage":"https://drive.google.com/thumbnail?id=1I9aZNR6RK0DvsM7LlgEJgie7KYbW07DN\u0026sz=w2048","abstract":"筋電位信号を用いた動作識別では，識別対象の全ての動作について訓練用データを収集する必要がある．しかし，実用上重要な多自由度の複合動作に関して，その全てをユーザから網羅的に計測することは非現実的である．本稿では，データ拡張手法であるMixupを利用した擬似データ生成により，複合動作を効率的に識別可能な手法を提案する．提案法では，基本動作時の計測信号と，その凸結合によって擬似的に生成された複合動作時の信号を識別器の訓練用データとして用いる．これにより，訓練用の計測動作数を抑えつつ，多様な複合動作を識別することが可能となる．実験では，健常成人から得られた筋電位信号を用いて提案法の有効性を検証した．"},{"title":"Bayesian Approach for Adaptive EMG Pattern Classification via Semi-supervised Sequential Learning","authors":["Seitaro Yoneda","Akira Furui"],"venue":"Proceedings of 2023 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","venueShort":"SMC","year":2023,"pages":"3310-3315","pdfUrl":"https://drive.google.com/file/d/1oV797VEcID4kGB3W_bw_GBQzg-KIQsI7/view?usp=sharing","codeUrl":"https://github.com/example/vision-survey","doi":"10.1109/SMC53992.2023.10394290","tags":["EMG","Bayesian Model","Machine Learning","Motion Recognition"],"type":"international","coverImage":"https://drive.google.com/thumbnail?id=1uAee2TeWZW83gupMBi2oWXTE7ILAMXXJ\u0026sz=w2048","abstract":"Intuitive human-machine interfaces may be developed using pattern classification to estimate executed human motions from electromyogram (EMG) signals generated during muscle contraction. The continual use of EMG-based interfaces gradually alters signal characteristics owing to electrode shift and muscle fatigue, leading to a gradual decline in classification accuracy. This paper proposes a Bayesian approach for adaptive EMG pattern classification using semi-supervised sequential learning. The proposed method uses a Bayesian classification model based on Gaussian distributions to predict the motion class and estimate its confidence. Pseudo-labels are subsequently assigned to data with high-prediction confidence, and the posterior distributions of the model are sequentially updated within the framework of Bayesian updating, thereby achieving adaptive motion recognition to alterations in signal characteristics over time. Experimental results on six healthy adults demonstrated that the proposed method can suppress the degradation of classification accuracy over time and outperforms conventional methods. These findings demonstrate the validity of the proposed approach and its applicability to practical EMG-based control systems."},{"title":"CNN-LSTMとプラーク表面情報を用いた超音波動画像中のJellyfish Sign自動識別","authors":["吉冨 孟志","久米 伸治","相澤 宏旭","古居 彬"],"venue":"第62回日本生体医工学会大会","year":2023,"month":5,"pages":"P1-24, p. 272","pdfUrl":"","tags":["Medical Image/Video","Ultrasound Imaging","Deep Learning","Time-series Analysis"],"type":"domestic","coverImage":null,"abstract":"【目的】頸動脈超音波検査により，非侵襲かつリアルタイムにプラーク病変の動的性状を評価できる．近年，血流の拍動によってプラーク表面が浮き沈みするJellyfish signという特徴が注目されており，この特徴を呈した症例の多くが脳梗塞を発症したと報告されていることから，Jellyfish signを早期に発見できれば有用である．そこで本稿では，動画像解析と深層学習を用いてJellyfish signを自動識別可能な手法を提案する．【方法】提案法では，まず計測された頸動脈超音波動画像に対して前処理を施し，血管壁全体の動きとプラークの動きを分離する．その後，前処理後の動画像と事前に検査者が指定したプラーク表面情報を結合し，CNNとLSTMから構成される深層ニューラルネットワークに入力する．これにより，プラーク表面の拍動性変化であるJellyfish signの特徴を考慮した識別が可能である．実験では，Jellyfish sign陽性100例，陰性100例のデータセットを用いて提案法の精度検証を行った．【結果】実験の結果，提案法は80％以上の精度でJellyfish signを識別可能であることが確認された．また，入力にプラーク表面情報を加えることで分類精度が向上することが明らかとなった．【結論】プラーク表面の情報を利用した深層学習が，Jellyfish signの自動識別において有効であることが示された．"},{"title":"Stochastic Fluctuation in EEG Evaluated via Scale Mixture Model for Decoding Emotional Valence","authors":["Shunya Fukuda","Akira Furui","Maro Machizawa","Toshio Tsuji"],"venue":"Proceedings of 2024 IEEE/SICE International Symposium on System Integration (SII 2024)","venueShort":"SII","year":2024,"pages":"567-572","pdfUrl":"https://drive.google.com/file/d/1hNDULCj1FHflD3najKaH4tWYXSMDVHbF/view?usp=sharing","codeUrl":"","doi":"10.1109/SII58957.2024.10417430","tags":["EEG","Probabilistic Model"],"type":"international","coverImage":"https://drive.google.com/thumbnail?id=1pnms4kRCGqJCmHZn7q0XmzxDbPnKydrL\u0026sz=w2048","abstract":"Electroencephalogram (EEG) analysis has garnered attention as a method for quantitatively decoding human emotions, and EEG amplitude values in specific frequency bands are typically used for this purpose. However, as brain states can fluctuate rapidly in response to external stimuli, accounting for temporal fluctuations in amplitude could enhance the accuracy of emotion decoding. In this paper, we investigate the relationship between pleasant/unpleasant emotions and fluctuations in EEG amplitude by utilizing a scale mixture model that assumes a hierarchical stochastic structure for EEG variance. This model focuses on the connection between the non- Gaussianity of the EEG amplitude distribution and stochastic fluctuation of the EEG variance (i.e., amplitude), which can be quantitatively evaluated by introducing a feature value. In the experiments, we used an EEG dataset obtained during the presentation of pleasant and unpleasant images and computed the proposed and conventional features, such as simple variance and approximate entropy values, for comparison. Statistical tests and receiver operating characteristic analyses of the calculated features indicated that the proposed feature, which reflects the stochastic fluctuation of variance, can distinguish between pleasant and unpleasant emotions more accurately than conventional features. These findings suggest that not only the conventional amplitude value but also its fluctuation, may be useful in assessing emotional valence."},{"title":"Epileptic seizure detection using a recurrent neural network with temporal features derived from a scale mixture EEG model","authors":["Akira Furui","Ryota Onishi","Tomoyuki Akiyama","Toshio Tsuji"],"venue":"IEEE Access","year":2024,"pages":"162814-162824","pdfUrl":"https://drive.google.com/file/d/1Up5QqDjI_b69VHX_th7DWfPE3IS0DIcy/view?usp=sharing","codeUrl":"","doi":"10.1109/ACCESS.2024.3487637","volume":"24","number":"11","tags":["EEG","Epileptic Seizure Detection","Time-series Analysis","Probabilistic Model","Deep Learning"],"type":"journal","coverImage":"https://drive.google.com/thumbnail?id=1uGnZYP0ZDP6hffBQyV64QEHzeEke0eA4\u0026sz=w2048","abstract":"Automated detection of epileptic seizures from scalp Electroencephalogram (EEG) is crucial for improving epilepsy diagnosis and management. This paper presents an automated inter-patient epileptic seizure detection method using multichannel EEG signals. The proposed method performs both feature extraction and seizure detection based on a scale mixture-based stochastic EEG model and a recurrent neural network, respectively. Specifically, the stochastic model that can consider uncertainties in the EEG amplitude is first fitted to a specific frequency band of EEG, thereby extracting relevant features of the seizure. Then, a recurrent neural network-based recognition architecture learns the temporal evolution of these features. We evaluated our method using EEG data from 20 patients with focal epilepsy, conducting comprehensive assessments including ablation studies on classifiers and features. The results demonstrate that our approach outperforms static classifiers and existing feature sets, achieving high sensitivity while maintaining acceptable specificity. Furthermore, our feature set showed efficacy both independently and as a complement to existing features, indicating its robustness in seizure detection tasks. These findings reveal that learning the temporal evolution of the stochastic fluctuation and amplitude information of EEG extracted using a stochastic model enables highly accurate seizure detection, potentially advancing automated epilepsy diagnosis in clinical settings."},{"title":"U-Netによる頸動脈超音波動画中のプラーク表面エッジの予測とJellyfish signの評価","authors":["廣池 友哉","吉冨 孟志","久米 伸治","相澤 宏旭","古居 彬"],"venue":"第63回日本生体医工学会大会","year":2024,"month":5,"pages":"P2-33, p. 317","pdfUrl":"","tags":["Medical Image/Video","Ultrasound Imaging","Segmentation","Deep Learning","Time-series Analysis"],"type":"domestic","coverImage":null,"abstract":"【目的】頸動脈プラークのうち，可動性を示すプラークは破綻の恐れがあり注意を要する．中でも，プラーク表面が拍動に応じて上下に変形するJellyfish signを示す症例は，破綻の危険性が特に高く，短期間のうちに脳梗塞の発症・再発を繰り返す可能性が高いため，早期発見が重要である．しかしながら，従来のJellyfish sign評価は目視による主観的かつ定性的な評価に依拠しており，十分な経験を有する一部の専門家でないと判別が困難であった．そこで本稿では，超音波動画からプラーク表面エッジの運動特徴を解析し，Jellyfish signを定量評価可能な手法を提案する．【方法】提案法では，計測された頸動脈超音波動画を深層ニューラルネットであるU-Netに入力し，プラーク表面エッジを予測する．その後，フレーム間差分処理を用いてプラーク表面エッジの運動量を計算し，そこから複数の運動評価指標を算出することで，Jellyfish signの特徴であるプラーク表面の動きを評価可能である．実験では，Jellyfish sign陽性群100例・陰性群100例のデータセットを用い，群間で各指標を比較した．【結果】陽性群において，運動量の平均値や変動幅に関する指標が陰性群に比べて有意に大きくなることが確認された．【結論】提案法を用いてプラーク表面エッジの運動を解析することで，Jellyfish signの特徴を客観的かつ定量的に評価できる可能性を示した."},{"title":"Finger-tapping Motion Recognition Based on Skin Surface Deformation Using Wrist-mounted Piezoelectric Film Sensors","authors":["Shumma Jomyo","Akira Furui","Tatsuhiko Matsumoto","Tomomi Tsunoda","Toshio Tsuji"],"venue":"IEEE Sensors Journal","year":2024,"pages":"17876--17884","pdfUrl":"https://drive.google.com/file/d/1I0swUhGAYh00wRJzwU4bljHVM1vIF5qj/view?usp=sharing","codeUrl":"","doi":"10.1109/JSEN.2024.3386333","volume":"","tags":["Piezoelectric Film Sensor","Movement Analysis","Motion Recognition"],"type":"journal","coverImage":"https://drive.google.com/thumbnail?id=1LjcEAKne88LLeDqHegqSZC8sURuMZFxL\u0026sz=w2048","abstract":"The miniaturization of computers has led to the development of wearable devices in the form of watches and eyeglasses. Consequently, the narrower screen size has raised the issue of operability for text input. This problem can be resolved using external input devices, such as physical keyboards. However, this can impair portability and accessibility. This study proposes a finger-tapping motion recognition system using wrist-mounted piezoelectric film sensors to realize an input interface with high wearability and not limited by screen size. In the proposed system, biodegradable piezoelectric film sensors, which are highly compatible with biological signal measurement, are attached to the palmar and dorsal surfaces of the wrist to measure minute skin surface deformation during tapping. The system detects the occurrence of tapping movements for each finger by preprocessing the measured signals and calculating the total activity of all channels. It also recognizes the type of finger movement based on machine learning. In the experiment, we measured ten different signals, including five-finger flexion and extension, for 11 subjects, to evaluate the effectiveness of the proposed method. According to the experimental results, tapping recognition accuracy for time-series data was 77.5%, assuming character input. In addition, the time difference between the detected and actual taps was approximately 50 ms on average. Therefore, the proposed method can be utilized as an input interface for wristband-type wearable devices."},{"title":"敵対的学習に基づく患者不変特徴を利用したてんかん発作検出","authors":["田﨑 莉菜","矢沢 樹","米田 清太朗","秋山 倫之","古居 彬"],"venue":"第25回計測自動制御学会システムインテグレーション部門講演会（SI2024）","venueShort":"SI","year":2024,"month":12,"pages":"2840-2845","pdfUrl":"","tags":["EEG","Epileptic Seizure Detection","Deep Learning","Domain generalization"],"type":"domestic","coverImage":"https://drive.google.com/thumbnail?id=1VZmhs2_Apo_ZuZD6AJoqthcnFthV9nj1\u0026sz=w2048","abstract":"This paper proposes an electroencephalogram (EEG)-based epileptic seizure detection method using patient-invariant features. The proposed method combines convolutional neural network (CNN) and bidirectional long short-term memory (BiLSTM) in a two-stage learning process. First, a CNN is trained to extract patient-invariant features through adversarial training with a label predictor and domain classifier. Then, BiLSTM is connected to the CNN and fine-tuned to capture temporal changes in the extracted features. This approach enables robust seizure detection that is less sensitive to individual patient differences. The proposed method was evaluated using data from 20 patients, demonstrating its effectiveness in generalizability across different patients."},{"title":"Inter-Subject Variance Transfer Learning for EMG Pattern Classification Based on Bayesian Inference","authors":["Seitaro Yoneda","Akira Furui"],"venue":"Proceedings of the 46th Annual International Conference of the IEEE Engineering in Medicine \u0026 Biology Society (EMBC2024)","venueShort":"EMBC","year":2024,"pages":"","pdfUrl":"https://drive.google.com/file/d/1XRIBVfBQjp2utSZnZtDlc0tL2c13sSTO/view?usp=sharing","codeUrl":"","doi":"10.1109/EMBC53108.2024.10782091","tags":["EMG","Motion Recognition","Bayesian Model","Transfer Learning"],"type":"international","coverImage":"https://drive.google.com/thumbnail?id=1uR5T7IzOWOKfq3A19BLkKZx57F6NpAjr\u0026sz=w2048","abstract":"In electromyogram (EMG)-based motion recognition, a subject-specific classifier is typically trained with sufficient labeled data. However, this process demands extensive data collection over extended periods, burdening the subject. To address this, utilizing information from pre-training on multiple subjects for the training of the target subject could be beneficial. This paper proposes an inter-subject variance transfer learning method based on a Bayesian approach. This method is founded on the simple hypothesis that while the means of EMG features vary greatly across subjects, their variances may exhibit similar patterns. Our approach transfers variance information, acquired through pre-training on multiple source subjects, to a target subject within a Bayesian updating framework, thereby allowing accurate classification using limited target calibration data. A coefficient was also introduced to adjust the amount of information transferred for efficient transfer learning. Experimental evaluations using two EMG datasets demonstrated th effectiveness of our variance transfer strategy and its superiority compared to existing methods."},{"title":"ベイズ逐次自己学習と尺度混合分布を用いた筋電位パターンの適応的分類","authors":["米田 清太朗","古居 彬"],"venue":"第25回計測自動制御学会システムインテグレーション部門講演会（SI2024）","venueShort":"SI","year":2024,"month":12,"pages":"1613-1618","pdfUrl":"","tags":["EMG","Bayesian Model","Machine Learning","Motion Recognition"],"type":"domestic","coverImage":"https://drive.google.com/thumbnail?id=1uSt40V_Ll3hWhWoxvJ0hl22iV3YTDf17\u0026sz=w2048","abstract":"In this paper, we propose an adaptive electromyogram (EMG) pattern classification method that integrates Bayesian sequential learning with self-training. The proposed method models EMG patterns using a scale mixture distribution framework to account for signal variance uncertainty. Leveraging this model, we estimate motion predictions and their confidence, achieving adaptive classification through Bayesian updating based on high-confidence data. The effectiveness of the proposed method was evaluated using both short- and long-term EMG datasets, demonstrating its robustness to temporal variations in EMG signals."},{"title":"Classification of Carotid Plaque with Jellyfish Sign Through Convolutional and Recurrent Neural Networks Utilizing Plaque Surface Edges","authors":["Takeshi Yoshidomi","Shinji Kume","Hiroaki Aizawa","Akira Furui"],"venue":"Proceedings of the 46th Annual International Conference of the IEEE Engineering in Medicine \u0026 Biology Society (EMBC2024)","venueShort":"EMBC","year":2024,"pages":"","pdfUrl":"https://drive.google.com/file/d/1us_-Jw3OP-xg1ny8ZWmgbJTmDWps-iqN/view?usp=sharing","codeUrl":"","doi":"10.1109/EMBC53108.2024.10782813","tags":["Medical Image/Video","Ultrasound Imaging","Deep Learning","Time-series Analysis"],"type":"international","coverImage":"https://drive.google.com/thumbnail?id=1Jk6706l62odCvk56EEaDeqyQqXUt8TBU\u0026sz=w2048","abstract":"In carotid arteries, plaque can develop as localized elevated lesions. The Jellyfish sign, marked by fluctuating plaque surfaces with blood flow pulsation, is a dynamic characteristic of these plaques that has recently attracted attention. Detecting this sign is vital, as it is often associated with cerebral infarction. This paper proposes an ultrasound video-based classification method for the Jellyfish sign, using deep neural networks. The proposed method first preprocesses carotid ultrasound videos to separate the movement of the vascular wall from plaque movements. These preprocessed videos are then combined with plaque surface information and fed into a deep learning model comprising convolutional and recurrent neural networks, enabling the efficient classification of the Jellyfish sign. The proposed method was verified using ultrasound video images from 200 patients. Ablation studies demonstrated the effectiveness of each component of the proposed method."},{"title":"プラーク表面情報を活用した深層学習によるJellyfish sign識別","authors":["吉冨 孟志","久米 伸治","相澤 宏旭","古居 彬"],"venue":"第25回計測自動制御学会システムインテグレーション部門講演会（SI2024）","venueShort":"SI","year":2024,"month":12,"pages":"2830-2835","pdfUrl":"","tags":["Medical Image/Video","Ultrasound Imaging","Deep Learning","Time-series Analysis"],"type":"domestic","coverImage":"https://drive.google.com/thumbnail?id=1WEOsjo9MvrdM84AzxjK8q7PbyS73xG99\u0026sz=w2048","abstract":"This paper proposes an ultrasound video-based classification method for the Jellyfish sign, using deep neural networks. The proposed method first preprocesses carotid ultrasound videos to separate the movement of the vascular wall from plaque movements. Subsequently, the preprocessed videos and plaque surface information are input to a deep neural network architecture integrating convolutional and recurrent neural networks. The model assesses plaque motion by fusing the features of the plaque videos and the plaque surface information, enabling classification based on the features of the Jellyfish sign, characterized by pulsatile changes of the plaque surface. We evaluated optimal feature fusion strategies using ultrasound video images from 200 patients."}]},"__N_SSG":true},"page":"/","query":{},"buildId":"J5Z9lYgfd6bhvVj4i3vci","assetPrefix":"/paper-repository","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>